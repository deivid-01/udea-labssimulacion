{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "lab4_parte1 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1tb9xQfodtj"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdariasl/ML_2020/blob/master/Labs/lab4/lab4_parte1.ipynb\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZt2JG85odtj",
        "outputId": "358c7edf-0fff-49e9-aa2b-107ec9107570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#for local \n",
        "#import sys ; sys.path.append('../commons/utils/')\n",
        "!wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py --no-cache\n",
        "from general import configure_lab4\n",
        "configure_lab4()\n",
        "from lab4 import *\n",
        "GRADER = part_1()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-03 23:22:50--  https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14117 (14K) [text/plain]\n",
            "Saving to: ‘general.py’\n",
            "\n",
            "general.py          100%[===================>]  13.79K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-11-03 23:22:50 (1.06 MB/s) - ‘general.py’ saved [14117/14117]\n",
            "\n",
            "lab configuration started\n",
            "installing libraries\n",
            "downloading files\n",
            "lab configured\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEFZ1bNsodtm"
      },
      "source": [
        "# Laboratorio 4 - Parte 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIyPCtR3odtm"
      },
      "source": [
        "Este ejercicio tiene como objetivo implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de regresión. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAVPFqINodtn"
      },
      "source": [
        "Para este ejercicio usaremos la base de datos sobre calidad del aire, que ha sido usada en laboratorios previos, pero en este caso trataremos de predecir dos variables en lugar de una, es decir, abordaremos **un problema de múltiples salidas**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1ILV7RModtn"
      },
      "source": [
        "#cargamos la bd que está en un archivo .data y ahora la podemos manejar de forma matricial\n",
        "db = np.loadtxt('AirQuality.data',delimiter='\\t')  # Assuming tab-delimiter\n",
        "\n",
        "#Esta es la base de datos AirQuality del UCI Machine Learning Repository. En la siguiente URL se encuentra toda\n",
        "#la descripción de la base de datos y la contextualización del problema.\n",
        "#https://archive.ics.uci.edu/ml/datasets/Air+Quality#\n",
        "\n",
        "x = db[:,0:11]\n",
        "y = db[:,11:13]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKlFuQyRodtp"
      },
      "source": [
        "Para calcular los errores, vamos a explorar y usar la el [modulo de metricas den sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Podemos observar que el modulo tiene metricas para regresión y clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFIUq69Modtp"
      },
      "source": [
        "## Ejercicio 1 - Experimentar con MLP paa regresión\n",
        "\n",
        "Para porder implementar nuestra función, lo primero que debemos entender es la estrucutra de la red. Como mencionamos, vamos a solucionar un problema de multiples salidas. Estas salidas con valores continuos. Por lo tanto debemos garantizar que la capa de salida del nuestra red tenga la capacidad de modelar. este tipo de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjF6liTmodtp",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿De acuerdo al problema planteado, que función de activación debe usar el MLP para un problema de regresión?\n",
        "respuesta_1 = \"Para un problema de regresion no se debe usar una funci\\xF3n de activaci\\xF3n en las salidas, la funcion de activacion solo se aplica en las capas ocultas y esta funcion sera de tipo...\" #@param {type:\"string\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G_bSsYcodtr"
      },
      "source": [
        "Una caracteristica de los modelos de sklearn, es que ciertos tipos de atributos, solo pueden ser accedidos cuanto se entrena el modelo. Vamos a realizar un pequeña función para comprobar cual es la capa de activación de los modelos MLP para regresión de sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Rd2sBnodts"
      },
      "source": [
        "# ejercicio de código\n",
        "def output_activation():\n",
        "    \"\"\"funcion que entrena un modelo\n",
        "    con data aleatoria para confirmar la funcion\n",
        "    de activacion de la ultima capa\n",
        "    \"\"\"\n",
        "    mlp = MLPRegressor(activation='identity')\n",
        "   \n",
        "    # fit with some random data\n",
        "    xrandom = np.random.rand(10,2)\n",
        "    yrandom = np.zeros(10)\n",
        "    # llamar el metodo adecuado para entrenar\n",
        "    # el mlp con los x y 'y' random\n",
        "    print(yrandom.shape)\n",
        "    mlp.fit(xrandom, yrandom)\n",
        "    # retornar el atributo de mlp adecuado\n",
        "    return (mlp)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzJDEC1Bodtt",
        "outputId": "0ace574a-3770-4533-e1e4-c425dd70194c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "#ignora las graficas!!\n",
        "GRADER.run_test(\"ejercicio1\", output_activation)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n",
            "...error inesperado....\n",
            "  es muy probable que tengas un error de sintaxis \n",
            " ...puedas que tengas una variable definida erroneamente dentro de la funcion... \n",
            "...este es el stack retornado...\n",
            " .... \n",
            "\n",
            "FALLIDO. revisa tu funcion. Sigue las instrucciones del notebook. Si tienes alguna duda pregunta!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/general.py\", line 322, in wrapper\n",
            "    return (func(*args, **kwargs))\n",
            "  File \"/content/lab4.py\", line 35, in test_output_activation\n",
            "    act = func()\n",
            "  File \"<ipython-input-6-e9156d3a7fbc>\", line 15, in output_activation\n",
            "    mlp.fit(xrandom, yrandom)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 641, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 326, in _fit\n",
            "    X, y = self._validate_input(X, y, incremental)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1388, in _validate_input\n",
            "    X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n",
            "AttributeError: 'MLPRegressor' object has no attribute '_validate_data'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ybj-1vodtv",
        "outputId": "235af2d0-efa2-4de6-a562-9bff269c8881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(\"la función de activación para un problema de regresion es:\", output_activation())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-43cc990f32b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"la función de activación para un problema de regresion es:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-e9156d3a7fbc>\u001b[0m in \u001b[0;36moutput_activation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# el mlp con los x y 'y' random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrandom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# retornar el atributo de mlp adecuado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    324\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n\u001b[0m\u001b[1;32m   1389\u001b[0m                                    multi_output=True, y_numeric=True)\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MLPRegressor' object has no attribute '_validate_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfyjpaF4MeSV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udcddNBiodtz"
      },
      "source": [
        "Una vez comprobado que sklearn usa la función de activación correcta, vamos crear la función para realizar los experimentos.\n",
        "\n",
        "Vamos completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de regresión propuesto.\n",
        "1. Como función de activación en las capas ocultas use la función 'tanh'. \n",
        "2. Ajuste el número máximo de épocas a 400.\n",
        "3. Dejamos como variables el número de capas ocultas y el número de neuronas por capa\n",
        "5. Selecciones la función adecuada del [modulo de sklearn para calcular el error absoluto medio](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics). Tener en cuenta que parametros usar.\n",
        "6. Debemos usar los nombres explicitos, por ejemplo si para el MLP es necesario usar el parametro `activation`, debe ser llamado: `MLPRegressor(activation=...)`\n",
        "7. Explorar que hace la siguiente linea de codigo `tuple(2*[100])`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-SdZ9H_odt0"
      },
      "source": [
        "# ejercicio de código\n",
        "\n",
        "def experimetar_mlp(X,Y, num_hidden_layers, num_neurons):\n",
        "    \"\"\" función para realizar experimentos con el MLP\n",
        "    x: matriz de numpy con caracteristicas\n",
        "    y: vector numpy con las variables a predecir\n",
        "    num_hidden_layers: list de enteros con el numero de capdas\n",
        "        ocultas a usar\n",
        "    num_neurons: list de enteros con el numero de neuronas a usar\n",
        "    \n",
        "    Retorna: dataframe con 6 columnas:\n",
        "        - numero de capas, numero de neuronas\n",
        "        - promedio de error prueba variable 1 y desviación estandar\n",
        "        - promedio de error prueba variable 2 y desviación estandar\n",
        "        \n",
        "    \"\"\"\n",
        "    #Validamos el modelo\n",
        "    Folds = 4\n",
        "    ss = ShuffleSplit(n_splits=Folds, test_size=0.2)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for hidden_layers in num_hidden_layers:\n",
        "        for neurons in num_neurons:\n",
        "            for j, (train, test) in enumerate(ss.split(X)):\n",
        "                # para almacenar errores intermedios\n",
        "                ErrorY1 = np.zeros(Folds)\n",
        "                ErrorY2 = np.zeros(Folds)\n",
        "                Xtrain= X[train,:]\n",
        "                Ytrain = Y[train,:]\n",
        "                Xtest = X[test,:]\n",
        "                Ytest = Y[test,:]\n",
        "                #Normalizamos los datos\n",
        "                scaler = StandardScaler().fit(X= Xtrain)       \n",
        "                Xtrain = scaler.transform(Xtrain)\n",
        "                Xtest = scaler.transform(Xtest)\n",
        "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "                # prestar atención a los parametros, correctos.\n",
        "                hidden_layer_sizes = tuple(hidden_layers*[neurons])\n",
        "                mlp = MLPRegressor(activation='tanh',hidden_layer_sizes= hidden_layer_sizes, max_iter=400)\n",
        "                # entrena el MLP\n",
        "                mlp = mlp.fit(Xtrain,Ytrain)\n",
        "                #Use para el modelo para hacer predicciones sobre el conjunto Xtest\n",
        "                Yest = mlp.predict(Xtest)\n",
        "                #Mida el error absoluto medio para cada una de las dos salidas\n",
        "                #Observe bien la documentación. recordar que esta resolviendo\n",
        "                # un problema de multiples salidas\n",
        "                errors = mean_absolute_error(Ytest, Yest, multioutput='raw_values')\n",
        "                ErrorY1[j] = errors[0]\n",
        "                ErrorY2[j] = errors[1]\n",
        "        \n",
        "            print('error para salida 1 = ' + str(np.mean(ErrorY1)) + '+-' + str(np.std(ErrorY1)))\n",
        "            print('error para salida 2 = ' + str(np.mean(ErrorY2)) + '+-' + str(np.std(ErrorY2)))\n",
        "        \n",
        "            resultados.loc[idx,'capas ocultas'] = hidden_layers\n",
        "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
        "            resultados.loc[idx,'error de prueba y1(media)'] = np.mean(ErrorY1)\n",
        "            resultados.loc[idx,'intervalo de confianza y1'] = np.std(ErrorY1)\n",
        "            resultados.loc[idx,'error de prueba y2(media)'] = np.mean(ErrorY2)\n",
        "            resultados.loc[idx,'intervalo de confianza y2'] = np.std(ErrorY2)\n",
        "            idx+=1\n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBVxxl25odt1"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "# ignorar los prints\n",
        "GRADER.run_test(\"ejercicio2\", experimetar_mlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV-ka-ukodt3"
      },
      "source": [
        "# tarda unos minutos!!\n",
        "resultados_mlpr = experimetar_mlp(x,y, [1,2], [8,12,16,20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7insQmbOodt5"
      },
      "source": [
        "# ver los resultados\n",
        "import seaborn as sns\n",
        "sns.relplot(data = resultados_mlpr,  x='neuronas en capas ocultas', y = 'intervalo de confianza y1', style= 'capas ocultas', kind = 'line')\n",
        "sns.relplot(data = resultados_mlpr,  x='neuronas en capas ocultas', y = 'intervalo de confianza y2', style= 'capas ocultas', kind = 'line')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpSvl_I4odt7",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿como influencian los parametros de numero de capas y el numero de neuronas? explique de acuerdo a los resultados, recuerde concentrarse en los patrones no en valores especificos\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY2yg06Nodt8"
      },
      "source": [
        "## Ejercicio 2 Experimentar con MLP para clasificación\n",
        "\n",
        "A continuación se leen los datos de un problema de clasificación. El problema corresponde a la clasifiación de dígitos escritos a mano. Usaremos únicamente 4 de las 10 clases disponibles. Los datos fueron preprocesados para reducir el número de características. La técnica usada será analizada más adelante en el curso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQQrTIcZodt9"
      },
      "source": [
        "digits = load_digits(n_class=4)\n",
        "#--------- preprocesamiento--------------------\n",
        "pca = PCA(0.99, whiten=True)\n",
        "data = pca.fit_transform(digits.data)\n",
        "#---------- Datos a usar ----------------------\n",
        "Xd = data\n",
        "Yd = digits.target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAZkhxDjodt_",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿Qué tipo de función de activación usa el modelo en la capa de salida para un problema de clasificación? \n",
        "respuesta_3 = \"La funci\\xF3n de activacion para un problema de clasificacion es softmax, generalmente es mas usada cuando el problema de clasificacion  es de mas de dos clases\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6VwPK9RoduA"
      },
      "source": [
        "como lo hicmos antes, vamos a comprobar con la libreria la función de activación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10TRJf1SoduB"
      },
      "source": [
        "# ejercicio de código\n",
        "def output_activation_MPC():\n",
        "    \"\"\"funcion que entrena un modelo\n",
        "    con data aleatoria para confirmar la funcion\n",
        "    de activacion de la ultima capa\n",
        "    \"\"\"\n",
        "    mlp = MLPClassifier(activation='logistic')\n",
        "    # fit with some random data\n",
        "    xrandom = np.random.rand(10,2)\n",
        "    yrandom = np.zeros(10)\n",
        "    # llamar el metodo adecuado para entrenar\n",
        "    # el mlp con los x y 'y' random\n",
        "    mlp.fit(xrandom , yrandom)\n",
        "    # retornar el atributo de mlp adecuado\n",
        "    return (mlp)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-JlGyNsoduC",
        "outputId": "09015e23-9066-4bca-b697-c29b4a4ab100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", output_activation_MPC)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...error inesperado....\n",
            "  es muy probable que tengas un error de sintaxis \n",
            " ...puedas que tengas una variable definida erroneamente dentro de la funcion... \n",
            "...este es el stack retornado...\n",
            " .... \n",
            "\n",
            "FALLIDO. revisa tu funcion. Sigue las instrucciones del notebook. Si tienes alguna duda pregunta!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/general.py\", line 322, in wrapper\n",
            "    return (func(*args, **kwargs))\n",
            "  File \"/content/lab4.py\", line 77, in test_output_activation_MPC\n",
            "    tests = {'explorar de mejor manera la libreria': act[0:2] == 'lo'}\n",
            "TypeError: 'MLPClassifier' object is not subscriptable\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR1AWh6doduE"
      },
      "source": [
        "print(\"la función de activación para un problema de clasificación es:\", output_activation_MPC())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUrb8sX1oduG"
      },
      "source": [
        "Ahora en nuestro siguiente ejercicio vamos a implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de clasificación. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPXRYrtnoduG"
      },
      "source": [
        "\n",
        "Vamos completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de regresión propuesto.\n",
        "1. Como función de activación en las capas ocultas use la función 'tanh'. \n",
        "2. Ajuste el número máximo de épocas a 400.\n",
        "3. Dejamos como variables el número de capas ocultas y el número de neuronas por capa\n",
        "5. Selecciones la función adecuada del [modulo de sklearn para calcular la exactitud del clasificador](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics). Tener en cuenta que parametros usar.\n",
        "6. Debemos usar los nombres explicitos, por ejemplo si para el MLP es necesario usar el parametro `activation`, debe ser llamado: `MLPClassifier(activation=...)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO3RLo4JoduG"
      },
      "source": [
        "# ejercicio de código\n",
        "def experimetar_mlpc(X,Y, num_hidden_layers, num_neurons):\n",
        "    \"\"\" función para realizar experimentos con el MLP\n",
        "    x: matriz de numpy con caracteristicas\n",
        "    y: vector numpy con las variables a predecir\n",
        "    num_hidden_layers: list de enteros con el numero de capdas\n",
        "        ocultas a usar\n",
        "    num_neurons: list de enteros con el numero de neuronas a usar\n",
        "    \n",
        "    Retorna: dataframe con 4 columnas:\n",
        "        - numero de capas, numero de neuronas\n",
        "        - promedio de error prueba (exactitud/eficiencia) de claisficacion y desviación estandar        \n",
        "    \"\"\"\n",
        "    #Validamos el modelo\n",
        "    Folds = 4\n",
        "    skf = StratifiedKFold(n_splits=Folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for hidden_layers in num_hidden_layers:\n",
        "        for neurons in num_neurons:\n",
        "            for j, (train, test) in enumerate(skf.split(X, Y)):\n",
        "                # para almacenar errores intermedios\n",
        "                Error = np.zeros(Folds)\n",
        "                Xtrain= X[train,:]\n",
        "                Ytrain = Y[train]\n",
        "                Xtest = X[test, :]\n",
        "                Ytest = Y[test]\n",
        "                #Normalizamos los datos\n",
        "                scaler = StandardScaler().fit(X= Xtrain)       \n",
        "                Xtrain = scaler.transform(Xtrain)\n",
        "                Xtest = scaler.transform(Xtest)\n",
        "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "                # prestar atención a los parametros, correctos.\n",
        "                hidden_layer_sizes = tuple(hidden_layers*[neurons])\n",
        "                #print(hidden_layer_sizes)\n",
        "                mlp = MLPClassifier(activation='tanh',hidden_layer_sizes= hidden_layer_sizes, max_iter=400)\n",
        "                # entrenar el MLP\n",
        "                mlp =mlp.fit(Xtrain,Ytrain)\n",
        "                #Use para el modelo para hacer predicciones sobre el conjunto Xtest\n",
        "                Yest = mlp.predict(Xtest)\n",
        "                #Mida el error absoluto medio para cada una de las dos salidas\n",
        "                #Observe bien la documentación. recordar que esta resolviendo\n",
        "                # un problema de multiples salidas\n",
        "                \n",
        "                Error[j] =mean_absolute_error(Ytest, Yest, multioutput='raw_values')\n",
        "        \n",
        "            print('error para configuracion de params = ' + str(np.mean(Error)) + '+-' + str(np.std(Error)))\n",
        "        \n",
        "            resultados.loc[idx,'capas ocultas'] = hidden_layers\n",
        "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
        "            resultados.loc[idx,'error de prueba(media)'] = np.mean(Error)\n",
        "            resultados.loc[idx,'intervalo de confianza'] = np.std(Error)\n",
        "            idx+=1\n",
        "    return (resultados)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcMLaM4coduI",
        "outputId": "af6d6895-90b0-4193-c506-0c790f3f225f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio4\", experimetar_mlpc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error para configuracion de params = 0.07142857142857142+-0.12371791482634838\n",
            "error para configuracion de params = 0.03571428571428571+-0.06185895741317419\n",
            "error para configuracion de params = 0.03571428571428571+-0.06185895741317419\n",
            "error para configuracion de params = 0.03571428571428571+-0.06185895741317419\n",
            "*** recordar usar la libreria de sklearn y llamar explicitamente el/los parametro(s) correcto(s)! ***\n",
            "FALLIDO. revisa tu funcion. Sigue las instrucciones del notebook. Si tienes alguna duda pregunta!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCyR-W0RoduJ"
      },
      "source": [
        "# tarda unos minutos!!\n",
        "resultados_mlpc = experimetar_mlpc(Xd,Yd, [1,2], [12,16,20,24])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FwrY7LFoduL"
      },
      "source": [
        "# ver los resultados\n",
        "import seaborn as sns\n",
        "sns.relplot(data = resultados_mlpc,  x='neuronas en capas ocultas', y = 'error de prueba(media)', style= 'capas ocultas', kind = 'line')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZJGmEnZoduO",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cuántas neuronas en la capa de salida tiene el modelo?¿Porqué debe tener ese número?\n",
        "respuesta_4 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGfDfjGkoduP"
      },
      "source": [
        "**nota rapida** En la practica sklearn no es una la libreria indicada para desarollar redes neuronales, para practicas mas avanzadas y realizar modelos en el \"mundo real\" [se deben usar conceptos de deep learning y una libreria llamada Keras](https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aRu5586oduP",
        "outputId": "5f78a2f7-ab2c-4796-fb72-22dc708b614d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "los tests estan incompletos! verifica el notebook\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL-i0zZyoduR",
        "cellView": "form"
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='1017251689' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOcAojtRoduT"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M_nkZ_DoduT"
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}