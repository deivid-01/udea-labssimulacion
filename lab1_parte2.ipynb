{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python36964bite6e4b44aef15498b8e6b096ea0e41af2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "colab": {
      "name": "lab1_parte2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyhyA0EkYySm"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdariasl/ML_2020/blob/master/Labs/lab1/lab1_parte2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras alamancenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "fYhyYxyrYySm",
        "outputId": "9ce435ea-cfdc-461a-d012-74d4f5f51e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "!wget https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py -O general.py\n",
        "from general import configure_lab1_p2\n",
        "configure_lab1_p2()\n",
        "from lab1 import *\n",
        "GRADER, x, y = part_2()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "--2020-09-18 12:40:48--  https://raw.githubusercontent.com/jdariasl/ML_2020/master/Labs/commons/utils/general.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11474 (11K) [text/plain]\n",
            "Saving to: ‘general.py’\n",
            "\n",
            "general.py          100%[===================>]  11.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-18 12:40:48 (85.0 MB/s) - ‘general.py’ saved [11474/11474]\n",
            "\n",
            "lab configuration started\n",
            "installing libraries\n",
            "downloading files\n",
            "lab configured\n",
            "cargando librerias y variables al ambiente\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0kgAjuBYySp"
      },
      "source": [
        "## Laboratorio 1 - Parte 2\n",
        "\n",
        "**Regresión logística**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0gwFeCnYySq"
      },
      "source": [
        "## Ejercicio 1: Contextualización del problema\n",
        "\n",
        "En esta sesión de laboratorio, vamos a resolver un problema de clasificación. Los variables que vamos a usar ya se encuentran cargadas:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "A-jBTrc4YySq",
        "outputId": "7b3f812c-861f-44c8-871a-2bf10453d175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "# tienes ya cargadas las siguientes variables:\n",
        "print(\"conjunto de datos, muestra \\n\",x[range(10), :] )\n",
        "print(\"\")\n",
        "print(\" muestra de etiquetas a predecir \\n\", y[range(10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conjunto de datos, muestra \n",
            " [[ 3.92606402 -6.83699086]\n",
            " [ 7.43382787 -3.7485991 ]\n",
            " [ 6.20553473  4.77182668]\n",
            " [ 6.77983287 -3.07765299]\n",
            " [-5.92614125 -4.87588843]\n",
            " [ 7.49283136  3.9516693 ]\n",
            " [-1.65572633  6.86081477]\n",
            " [-8.14881988 -1.85421149]\n",
            " [ 8.12616581 -1.66701921]\n",
            " [ 9.73411311 -1.63724335]]\n",
            "\n",
            " muestra de etiquetas a predecir \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lvqd4i0YySs"
      },
      "source": [
        "#Ejercicio de Codigo\n",
        "def clases_muestras_carac(X, Y):\n",
        "    \"\"\"Esta funcion es encargada retornar el numero clases, muestras \n",
        "        y caracteristicas del conjunto de datos X y Y\n",
        "\n",
        "        X: matriz numpy con el conjunto de datos para entrenamiento\n",
        "        Y: matriz numpy con el conjunto de etiquetas\n",
        "        retorna:\n",
        "            numero de clases (int/float)\n",
        "            numero de muestras (int/float)\n",
        "            numero de caracteristicas (int/float)\n",
        "    \"\"\"\n",
        "    ##Pista: es de utilidad el metodo np.unique ?\n",
        "    N,nf = X.shape\n",
        "    clases = len(np.unique(Y))\n",
        "    \n",
        "    return (N,nf,clases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "jBS6kWmkYySu",
        "outputId": "5dbec1cd-d62a-4935-e8f1-7501d6104ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio1\", clases_muestras_carac)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST EXITOSO!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8zabv6IYySw"
      },
      "source": [
        "En los problemas de clasificación, que lo permiten, es de utilidad visualizar los datos. De esta manera uno puede determinar que modelos o algortimos pueden tener mejor rendimiento. En la siguiente función, debera, graficar los datos usando la función [scatter](https://matplotlib.org/gallery/shapes_and_collections/scatter.html) de matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RLgNXDMJVb7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjiRibSVYySw"
      },
      "source": [
        "#Ejercicio de Codigo\n",
        "def scatter_plot(X, Y):\n",
        "    \"\"\"Esta funcion es encargada de graficar usando un scatter plot\n",
        "       un problema de clasificacion.\n",
        "\n",
        "        X: matriz numpy con el conjunto de datos para entrenamiento.\n",
        "           esta debera ser usada para los ejes del grafico. puede asumir\n",
        "           que solo va tener dos columnas\n",
        "        Y: matriz numpy con el conjunto de etiquetas. Debera se usada\n",
        "           para mostrar en diferentes colores, las etiquetas de cada una\n",
        "           de las muestras\n",
        "        retorna:\n",
        "            grafica matplotlib\n",
        "    \"\"\"\n",
        "    ## puedes accerder con plt al funcion adecuacada\n",
        "    ## Pista: recuerda como indexar matrices\n",
        "    ## Pista: recuerda el uso de np.ravel\n",
        "    x1 =X[:,0]\n",
        "    x2 =X[:,1]\n",
        "    colors = Y\n",
        "    plt.scatter(x1,x2, c=colors)\n",
        "    # para mostrar el grafico\n",
        "    figure =plt.gcf()\n",
        "    plt.show()\n",
        "   \n",
        "    return (figure)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "5fdDHIH0YyS0",
        "outputId": "3eea0e23-9a5a-4cbc-f9f5-3a782b9d2344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "# ignora los graficos que se muestran \n",
        "GRADER.run_test(\"ejercicio2\", scatter_plot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hTZfvA8e/J7qC0tAVKy5S9lL1kCLKUIYIslaUyBBUVXIAvUwVRtoIIqDhQQIYKCip7L9l7txRaSunMznn/KFZCUuhImiZ9Ptf1u34vJ+k5N5jeOecZ9y3JsowgCILg/RSeDkAQBEFwDZHQBUEQfIRI6IIgCD5CJHRBEAQfIRK6IAiCj1B56sJhYWFyuXLlPHV5QRAEr3TgwIGbsiyHO3vNYwm9XLly7N+/31OXFwRB8EqSJF3O6jUx5CIIguAjREIXBEHwESKhC4Ig+AiR0AVBEHzEAxO6JEmLJUmKkyTpWBavS5IkzZYk6ZwkSUckSarr+jAFQXCVyyejObb9JPo0g6dDEVwsO6tcvgLmAt9k8XpHoNKd/2sEfH7n/wuCUIDERycwttOHxJyLRalSYrXYGDztObq83MHToQku8sA7dFmWtwK37vOWrsA3cobdQLAkSRGuClAQBNcY8+QHXDp+FWO6ifRkPcZ0I1+89S1Htp7wdGj5xmK28POs33ip1hsMrPoa301Z4VNPKq5Yhx4JXL3rz9F3jsXe+0ZJkgYDgwHKlCnjgksL3k6WZY7vOMXRbacIKVGU5j0aExDk7+mwfM6l41eJPX8Dm9Vmd9yYbmT59LXEXbmJIc1Igw6PUKKs0z0rXk+WZf7XbRqHN5/AmG4E4PsPVrFj1V7m7P4QpUrp4QjzLl83Fsmy/AXwBUD9+vVFIfZCzmK28H7XaRzddgKTwYxGp2H+G18z9c/3qVL/IU+H51OSbiajVDtPWHt+O8jhzcex2Wx8/rpMr7efot//euZzhO53et85jmz5L5kDmPQmrp6JZdcv+3m0m/ePFLtilUsMUPquP0fdOSYI97X+y784svU4hjQjNqsNQ5qBtOR0JvaYjmi84lqV6lbAYrI4fU2WZfSpBozpJkwGMz99vJYTu07nc4Tud3L3WawWm8NxQ6qBYztOOf0Zk8HEid1nuHraO1KaKxL6WqDfndUujYEkWZYdhlsE4V6/L9mEMd3kcDw5IYXLJ6I9EJHv8i/ix6AP+qD112YeU6mVSJLk8F6T3sSGrzfnY3T5I7RUCCqN46CExk9D8dJhDsd/X/I33Yu/wLsdJjOs7lsMrTua+OiE/Ag11x445CJJ0g9AKyBMkqRo4H+AGkCW5fnAOuAJ4ByQDgx0V7CCb7nfXbi4Q3e9p1/rRPlaZVk1ax2JcUmULBvOnnUH0afaTwrKsozJYPZQlO7TuHN9tDo1hlQ9d3+8lCoFbZ5tbvfek3vOMveVxXbDMxePXuHdDpNZePRTp1+EBcEDE7osy30e8LoMDHdZRIJTF45cJiE2kcr1KlA0LMjT4bhE+wGtuHIyxu6XBiAwJIByNUpn8VNCXtRpXYs6rWsBkJKYSu/IwQ7v0QXoeKx3s/wOze00WjWfbp3IxGc+4dq560gKiZASwYz5YaTD79Sq2esw6e2fHm1WGzcux3P+8CUqPlI+P0PPNo9VW/RmVquV4ztOo0/RU7N5Nbeuyki8cZt3O04h5mzG2mGz0czTI59k0JS+Ob5LkGWZk7vPcHrfeUqUDafhE3VQqT33EXjipcfZsXofJ3efxZBuQOunRalU8P7yUQX2DsiXFAkJZMTcF5j7ymKsZis2qxWtv5YmXepRv/0jng7PLUpXiWThkU+JuxKPxWwlokIJp5+1hJhbTp8SlSolSfHJ+RFqroiEnkMXjlzm3Y6T0acakCQJi9nKsBkD6DS4rVuuN/GZT7h07CpWizXz2Oo566n4SHla9mya7fOYjGbGPPEBp/ZmTAypNEr8g/yZuW0SJcsVd0foD6TWqJm6YRyHNx/n6LaThJQIplWvpgQGB3gknsKo46A21Hq0Gn9+u5X0FD3NujakdsvqPv+FWrzM/ZdmNupUj9P7zmG85y7dbDRTpUFFd4aWJ5Knxirr168ve1s9dKvFSu+oIdyOS7I7rvXT8OnWiVSu59qldjdjEuhf6RWn45nVGldi9s4Psn2ubyev4IcPV9k9RioUElUaVWL2jikuiVcQfEVacjpD64zmVmxi5u+fLkBL3zHd6fNON4/GJknSAVmW6zt7Tdyh58DhzccdxtUg41v7ty/+pPIC1yb01NvpdzY7OCb0lFupOTrX74v+dhwTtMmcPXCB5IQUgkKL5CVUQfBa6Sl6Vs74lS0/7UTrr6Xr8A48/nwL5h+cxqo569m5eh9Fw4rw9MgnadChjqfDvS+R0HMgLSkdnDyJ2mwyKQkpLr9e6SqlnC6zUmlUNOni9As6S3cP2dxNkrJ+TRB8nclg4tUm7xF74UbmnficEV9ybPsp3lg4lOfG9uC5sT08HGX2ifK5OVCrRTXMRsfNGboALc3us8ts3x//MKr1ePpXfoVPB8/nxuX4bF1PqVIycv5gtP4aFIqMbxKNTkNw8SB6vfVUjmJv1bsZaq3jl0NkxQhCSgTn6FyC4Cs2/7iTG5fj7YY1DWlG/vpuK9fOX/dgZLkj7tBzIDi8KP0n9GTpxBWY9EZkOSOZV6hdlhbPNHb6M79+sZH5b3yduTTvxqU4tq3YzfxDH2erZkaLHk0oVbEkP8/6jRuX4mnQ/hE6DW2X44nD58Z2Z++6g8RfTUCfakDrr0GlVvHOt6/m6DyC4EsObDyMIc3ocFypUnJ852lKPVTSA1HlnkjoOdTrraeo3qQKvy7YQOrtdFo+04TH+jRDrVE7vNdkNLNw9FK7ddZWi430FD3fTl7BmwuHZeuaFR8pz1tLRuQp7oCiAcw/9DE7V+/j+K6MD2qbZ5tTJCQwT+cVBG9WvHQYKrUKi/meJ29JIjQixDNB5YFI6LlQq3k1ajWv9sD3xV64gYzjKiKb1cbhTcfdEdp9qTVqWvZsmqPljoLgy54Y/Dir5qy3S+iSQiIwOICHH6vhwchyR4yhu1FweFCWBZFCI73v218QfE1E+RKM/3k0wcWD8AvUofHTUL5mGT7ZNB6l0vvK6Yo7dDcqGhZEgw512Pf7IbvJVK2/lt5ve3Yta0FlMVv44aNV/DZ/I4b0jPrcL0197oEbQQQht+q3e5hlMV9w5WQMugAtEeVLeDqkXBMbi9xMn6rno+fnsO/3f1BplCDDix89K9p+ZWFCj+nsW38oc4eeQqmgSEggi0/NJKiYWCsvCGJjkQf5BfoxYdVb3I5PIvFGEpGVItBoHSdQBYg+G8vedQftlpDZrDb0aQbWffEnvXO5Q+/6pTiWjFvGob+OElQskGfe7EK7Aa18fnu78J+bMQn88dUm4q/eok7rmjTr1tCjdYzcxff+RgVUcHhRgsOLejqMAu3C4UuoNCqHUgcmfUaTgdy4ee0Ww+q9RXpSOjabTOL128x9ZRFXTsfw0kfPuSJsoYD7Z9MxxnX5CKvFitlo4e/vt7Fs6mpmbJuE7q768L5ATIoKBUaph0o69LyEjJ2xZatH5eqcKz79JaMjku2/oUVDupHVs9eRfMv1u3uFgsVms/FB35kY0oyZ81j6VANXTsWwes56D0fneiKhC24Re+EGi8d8z7SBc9m0bAdm04MbJlSsU55yNUo7lDtQa1R0HtY+V3Ec3XLC6UojtVbN5eOiK5Kvu3wiGn2aweG4SW/i7++3eSAi9xIJXXC5Pb8d4KXab7B8+lo2fr2FTwfP57WmYzDqHXfk3evD38fStGsDVBoVSpWS8rXLMu3P9522CMuOUpUikBSOY+Vmo5nw0qG5OqfgPdRaNbLN+cIPjZ8mn6NxPzGG7oOO7TjF568v4fzhyxmTgKO60P31TigU7v/+tpgtTO03x65XqCHVwJWTMfzy+QZ6vNH5vj8fGBzAuB/fwGQ0YzFZ8C/il6d4eo7qwq61++ziUWtV1GpezWN14IX8E1mxJMXLhBN9Osau7ZwuQEunIe08F5ibiDt0H3Pu0EXeaT+JM/svYDVbSbyRxNf/+4lF732fL9c/f/gyFied1Y16E5uW7cj2eTRadZ6TOWR0ux/zw+uERoSg8dOg1qho3Lk+768YledzCwWfJEmM/3k0RcOL4l/ED62/Bo2fhqZdG9Cuf0tPh+dy4g7dxyyduNyh7rkx3ciaOet5bmx3/ALzniTvR+unQbY5JnTIuCtyt9TbaexdfwiABh0eoUhIIE0616fRk3W5FZuIf5D/fb8oZFnmjyWbWDHjF1IT06jf/hH6T+hFeJQYnvFWZapG8sPV+exdf4jE67ep+WhVylb3zZ61IqH7mAuHL+Nsr5hCpSTuyk23f5DLVo+iWEQIseevOzzidh7q3kfcTT/uYPqgz1CqMh48rRYboxa/zGO9mqFQKAiLfHBSXjD6G36dvzGzoNqfS7ew65f9fHlsBiHFxbJTb6VSq2japYGnw3A7MeTiY8pUj8LZfhmr2UJ4LicWc0KSJCaueZvg4kXxD/JDF6hDo1Pz+PMt3VoU7Oa1W0wf+BkmvQl9igF9igGT3sT0gZ9xMyYhW+e4HZ/E2nl/OFTH1KfoWT17nbtCFwSXEXfoPqbf/57h8OZjdpOAWn8tHV9o7ZIx6XvZbDZ+X/Q3v8zfgMlgolWvZnR/vRPfX5nPgY1HuB2XRK3m1dxeV3rr8l3gpLIlyGxdsZunX3vygee4cOQKGp0as9F+iaXZaOGfTcdcE6gguJFI6AVQWlIaX7z1LZuX7cBqtdGkcz2GzRhAsZIPrtBYpUFFJq55h3mvLuLKyRgCivrz9MgneXZsd7fEOq3/XHas3pvZJGDZR6vYunwX8/ZPpdETdd1yTWdMehNWJ5OxVovNaR9YZ4qXDnW6Zl2hkChVKSLPMQqCu4mEXsDYbDbeaPU/rpyMyUwu21bu5vjO0yw5NQut34MnFuu2qcWi4zOx2WxuXap45VQM237eY5cwTQYz1+90ZWrzbHO3XftejTrVY+mkFQ79UVVqJY2ezN4XS1TlUlSu/xAn95y1S+xqnZoer3dyabyC4A5iDL2A+WfTcWLP37BLKFaLjdTENLYu352jc7l73fmJXWcye53ezZBm5NBfR9x67XuVr1mGzsPaofXXIkkSkiRlrDUe2pbytcpm+zwT17xNg/aPoNaq0PppCI0IYdyPb/DQw+XcF7wguIi4Qy9gLh27gsVsdTiuTzVw7p+LtO1XcNbOFisZjOTkS0OtVRFexv0TsPcaOr0/j3ZrxN/fb0OWoU3fR6n56IM7S90tMDiAiWveJvV2GunJ6YRFhebLhixBcAWR0AuY0lVKodIoHSbmdAHaArd2tl7b2gQE+WFIM9htr1aqlHR8oY1HYqrZrCo1m1XN83kCgwNy3IhbEDxN3HoUMHXb1qZYyRCU6v/aXykUGcMHj/UuWL1AlSoln2yeQPmaZdD4adAFaCkWEcykte/kuPbK5ZPRLJ24nK/H/8iFI5fdFLEg+DbRsagAuh2fxOyXF7JzzX5kWaZO65q8Nn9wgW6Ndf1SHEa9idJVSuV4iOLHj9fwzfifsJotyHJGdcUeozozYEJvN0UrFERGvRGTwUyRkEBPh1Kg3a9jkUjoBZjNZkOWZa9sVptdsRdv8GKN1x2aWmj8NMzb+xHlahSsYSbB9dKS0pgx5At2rN4LskzJ8sV5Y+EwajXP2fxHYXG/hJ6tWylJkjpIknRakqRzkiS94+T1MpIkbZIk6ZAkSUckSXoir0ELGatUfDmZA+xas99pqQKr2cL2VXvyPyAh343rMpWda/ZiMVmwmK1En4nlvSemEHMu1tOheZ0HJnRJkpTAPKAjUB3oI0lS9XveNhb4SZblOkBv4DNXB3qvc4cuMrbzh/SKHMzI5mM5sPGwuy8puIFCqXBaqgBJQqVSYjKYuHziqugu5KMun7jKmf3nM7sJ/ctstLBKlFvIsezcoTcEzsmyfEGWZROwDOh6z3tkIOjO/y4KXHNdiI5O7z/PyObj2LvuILdiEzm+4zT/6zaNTT9mvzyrUDA8+nRDp8eVKiVpyXq6F3+BV5q8R+/IIUzpOzNbTTIE73H9YpzdAoB/WS1WrpyM8UBE3i07CT0SuHrXn6PvHLvbeOA5SZKigXXAK85OJEnSYEmS9kuStD8+Pj4X4WZY+PZSjOlGu0d1Y7qJ+a9/hafmBITcCYsM5ZV5L6LRqdH6ZdSq1ujUPNa7Gatnr8OQmlFoy2w0s3P1XmYNW+jpkAUXKl+7LOYsWgTWaFbFAxF5N1ctW+wDfCXLchTwBLBUkiSHc8uy/IUsy/VlWa4fHh6e64udPXDB6fHkW6mk3k7L9XkFz+gwsDXfnJ/HkOn9GDzteZacns35fy5hSLe/GzcZzGz+cSfpKXoPRSq4WvHSYbTs2RSt/3/t4BQKCV2gli4vd/BgZN4pOxuLYoC7lxpE3Tl2txeADgCyLO+SJEkHhAFxrgjyXqERIaQnO/5SK1VK/AJ17rhkoZV6O4346ARKlgt3a3OM0IgQu0bQt2ITnb5PoZBITUx1S+XInMqvfxtfN2rRMMrXLMOauetJT9FTv93DvPDhs6L+fC5kJ6HvAypJklSejETeG+h7z3uuAG2AryRJqgbogNyPqTzAs2N7MGPIAru61Vp/DZ2HtUOlFptfXcFitjBnxCI2frMZhVKJzWrjmTc7M2BSbySns5iuVePRqmz/eY9Dg1+tv5bQyGJuv/79WC1W5oz4kg3fbEGtVmGxWOn26hO88EHffPm38TVKpZKeo7rQc1QXT4fi9R445CLLsgUYAfwBnCRjNctxSZImSpL073+BN4GXJEk6DPwADJDdOJjd5tnmDJjUG/8ifugCtGj8NHR8oQ0vfvisuy5Z6Cwe8wN/fLUJs9GCMd2I2Wjmhw9X8d3kFfly/YGTeqML0KFQ/vcR1fprGDZzgMeXci4Z+wN/frsVs8FMeooek97E6jnrWT1HrMoQPMurNxaZTWZuxd6maHgQOn/396ssLGw2G50Dn3PY7AOgVClYb1yWL3ei0Wdj+W7yCo7vOE2JcuH0efdp6rap5fbr3o8sy3Qt2g99qsHhtbDIYvxwdYEHoir4EuOSOLXnLMHFi1K1YUXxJJMH99tY5NXjE2qNmhJlcz+5KjhnNpqdJnPIKOV7Zv95qjSo6PY4oipF8PbXThdMeYzZZHGYrP1XcoJYK+/MkveXsfzjtai1KmSbTLGIYKZueF/87rqBKM4lOND6ZQxjOaNQKrgdl5TPERUcGq06y3Z6les/lM/RFHw71+7j5xm/YjaaSU/Wo081EHv+Bu93nerp0HySSOiCU22fb+H0uCRJpCWlF+qlgyPmvIDWX5O5w1VSSGj9tQz9pL9nAyuAVs9Zn9me8F82m0zMuViiz7h1/2GhJBK6h8iyzK3riejTHMdiC4Ih0/sRFhWKdE9HIkkhMevlhfQs+SJ/fL3JQ9F5Vv12DzP97/E0fLIepR4qQfPujZmza0q+DEN5m5TEVKfHlSplvuwZMRnNmIzOhw99kVdPinqrXb/sZ9awL0i+lQqyTIseTXht/mD8AgrWGvq0pDRWz13PtpV7uHTsikMTZq2fhnn7p1K2WpSHIhQKuu8/WMl3k1c6zMn4B/mx/MYiNFq1W64bdyWeT16cz+HNx5FlmdotqzNq0cs+MW6f52qLguuc3neOKX1mkHAtEbPBjNloYevK3XzYd5anQ3MQUDSAZ8f04Pn3n3HanNpitvDHkr89EJngLbqO6Eh46bDMnaAKhYTWX8Nrnw92WzI3Gc282nQM/2w6htVixWa1cWTLCV5t8h4mg+nBJ/BiXr3KxRstm7oak97+Q2U2mDmw8TA3YxIIiwz1UGRZS0tKR5ZtDsetFhspt5w/UgsCQECQP58fnMbvi/9m77pDhEUVo+vwDlR8pLzbrrlj1V7SU/TYrP99Zm1WG/pUA9t/3kPrvs3ddm1PEwk9Hx3feZp9vx9yWv9bpVUTd7VgJvQ6bWphMTsmdF2gliZdGnggIiGn9q4/xMoZv3I7LokmXerz9MgnCSpWJF+u7Rego9srT9Dtlfxpk3Dt/HWHiVgAfZqBmHPX8yUGTxEJPZ+c2nuWt9tNwpju/JHPYjRTttq9RSztRZ+5xtYVu7HZbDzarVG+dfMJjwql19tdWT59bWb8ugAt1ZtUodGTdfMlBiH3lk1dxXeTV2YmuaunY9j4zRYW/DPdJxthV6hdFl2AFn2K/YIDvwAdFWqX9VBU+cPrxtCNeiOJN257XZncJeOW2dWeuZvWX0P31zsRUDTrX64VM35lyCOj+Gb8T3w7YTkjGr7D0onL3RWug8hKEVgtNpQqJQqlAqvFRrfXnvT4Nnzh/tKS0lg6YbndHavZaOF2XBJrP/vdg5G5T8Mn6lC8dBhqzX/3qyqNirCoUBp3qufByNzPaxK6UW/k40Hz6FZsIM+We5k+UUO8qkXZhcOXnB6XJIn+43sxcHKfLH/2+qU4loz5HpPBjNVixWq1YdSb+HHqai6fuJrlz7lK7MUbzBi8AIvJkjnJZDaamdzzU1GuuIA7e/AiaieTjyaDmT3rDnkgIvdTKpXM3D6Z9gMfIzAkgMDgANoPeIxZOyajVPn2DYjXJPRpA+axedkOzEYzZqOZhNhEPnp+Nid2nfZ0aNkSUb6E0+MaPw1dR3S4b22LnWv2OR13t5gsbF+111UhZumv77Zhs1gdjksKKV+uL+RecPGiWMxO/ttJEFYqxAMR5Y/A4ABe+3wwqxK+YtWtrxg5fzBFQgI9HZbbeUVCT4xLYtfa/Q5rWU16Ez98uMpDUeVMvwm97Ir4Q0Yp2K7D26PROd9m/y+FIou+mwoJhcL9/wn1KXosThK6zWrFUEA3RgkZytUoTVTlCJQq+8+Jxk/D0yM7eSgqwV28IqHfjE5ArXWcv5VlvGbWun67hxm1+GXCIouhVCnwK6Kj+xudGPTBvaXlHTXrlkXfTaWC5j0auzpUB00613dezVKGBh0ecfv1hbyZ8tt7VKpbAa2fBv8gP/yL+DFizgvUaOr7Ld4M6UYWjP6G7uGD6Fq0Hx8+N4uELJqn+AKvWOUSWSkCq5PHRoVS4VV9B1v1bEbLZ5qiTzWg9ddke0IxPCqU4bMHMe/VxRnPynfGXwZ90JeoShEujTHu6k3mjljE3vWHUCgVNO/emJdnDeDRpxux/ec9GNKMSBJo/LR0e7UjkRVde33B9UIjQpiz+0NiL9wgOSGF8rXKPPCp0BfIssx7T0zh1N5zmO883W/5aSeHNx9nyalZPtllymu2/n8z4SeWf7w2s3SpJEnoAnUsOPQxERWcj0/7mvjoBHas2ovNZqNp1waULFfcpefXpxkYUPlVbsclZW7KUKmVRFaKYMHh6RzceIRNy3agVCtp168VtZpXc+n1hcLn1vVEfpq+loMbjxAWFUrPUV145LGaLjn3qb1nGd1mgsOadF2AliHT+9NpSFuXXCe/+UQ99Offf4YSZcP56eM13I5LplaLagya0rfQJHPIuFN/6pWObjv/lh93kp5sv8POYrYSd/Umh/46RoMOdWjQoY7bri8ULgmxiQx5+E3SkvVYTBYuHr3CkS0nGD5rIB1faJPn8184cgWc3K8a0oyc3nvWaxP6/XhNQpckifYDHqP9gMc8HYrPunjsitNJTovJwpWT0dRv97AHohJ81bIPV5GWlG63CseYbmT+G1/T5rkWea71UuqhEg7VQiGjqFzZfNqUl9+8YlJUAH2qnt++2Mjs4Qv5dcFG9Kmur0devlZZdE4qPqo0KsqIioqCi+3feNjpkkoZmejTea+VXrtldYqXCUOp/m+uSpJArVXTrn+rPJ+/IBIJ3QvEXYmnf6VXmf/m1/zy+QYWjPqafhVf4cbleJdep1WvpvgH+dk1ZlZpVBQvE07dxz3by1PwPcVKBjs9bjVbKRoelOfzKxQKPtk8gcad6qFUZ+xwrtqoMjO3TyIoNH/q2OQ3rxlyKczmvrqYpPgkbLaMAUFDmhGTwczs4V8y5dd3XXYdnb+WuXs+ZO4ri9i77mDGKpceTXh55oB8We8uFC49R3XhzL7zdj1aVRoVNR+thizL/DhtNbfjk6nX9mHqPl4rV5/BomFBjF85Gos5Y5ezszLQvsRrVrnkB6vFys61+zm8+ThhUcVo+3xLQiM8v5uuo64PFpPF4bhSpWC9cZnooC54rZUzf2XJ2GUoVQosJgvVm1Sh87B2TBswL7PEhC5QR42mVZjy67s+v3U/O+63ykUk9DuMeiNvtPwfV07FYEg1oNGpUSgVTPntPWq3qO7R2DoFPItR71ilUa1Vs07/vQciEgTXMaQbuXz8KiElihJSMpieJV9yqBGkC9AyYs4LYlEEomNRtqyes57Lx69iSM1Y5WEymDGkGfmg70xsNsda4PmpZc+mqDT2o2MqjYoWzzTxUETeISUxlRlDFvBUSH+6Bvfjkxc/IzkhxdNhCffQ+Wup0qAixcuEc3rvOae/b4Y0Ixu/2eKB6LyLSOh3/PXdNqd3wWlJeq6cjPFARP8ZNmMAZapF4heoQ+OnwS9QR1TlCIbPGujRuAoyq9XK683HseHrzaQlpZOerOfPpVt5tekYLGbH4SuhYFColFmWxr73pkZwJP6F7sjqwyLLNo9/kAKDA5h/8GMObz7O5RPRlKkWySOP1fS5sXOrxcr5w5fQ6DSUrR6Vp7/f/t//Ie7KTbu5B4vZyq3YRHat3U/z7u6vgSPkXJUGD6Hzd2xOoQvQumSzUXalJaWx5addJFxLpHrTytRpk7tJ2fwmEvodnQa35bPXv7JrQiFJEF46jMiKJT0Y2b+xSDzyWE2XbYsuaPasO8jUfnOwmK3INhvFIkKYuOZtyuZy/fuFI1ecPnHpUw1cPHpFJPQCSqlUMnHN27zTfjI2qw2rxYqkkGj5TBNa5EMhOoCzBy8wuvUELBYrxnQjukAdleqU56MN49zW2NpVREK/o/2gxzjw5xH2/HYA2SajVCvR6DSM/3m0z90JFzSxF28wqeendl+mseevM7r1eL6/Mh+VOucf08hKJdH6a5jQZL0AACAASURBVBzbkAXqiHRxQTPBtao2rMQP0QvYuXofyQkpPNK6JuVrlsmXa8uyzKSen5KWnJ55zJBq4PT+86yes56eo7rkSxy5JRL6HUqlknE/vsH5w5c4vuM0ISWDafRk3QL/jewLfl/8N9Z7xrVlGYzpJg5sPEKjJ3Let7RJl/oEBgdgTDdl1qZRKBX4Bepo3r2RS+IW3McvQEebZ5vn+3Wvnb/OreuO5XVNehMbvt4sErq3eejhcjz0cDlPh1Go3Iy55XQLuM1mI/FGUq7Oqdaomb1zCp++tIADfx4GoM5jNXn9i6GFonSskDv3exr3hgd1kdAFj6vf7hG2Lt/lUObUZrVRu0XuS/SGRYbywbr3sJgtyLKMWiOetoT7i6hQgtBSxbh2T+McrZ+GDgML/hr4bE3bSpLUQZKk05IknZMk6Z0s3tNTkqQTkiQdlyRJ7HYRsq1590aUrhqJ1u+/O2ddgJbH+7Wk1EN5n5BWqVUimQvZIkkS7y9/k8DgAHSBOhRKBbpAHdWbVKbL8A6eDu+BHrhTVJIkJXAGaAtEA/uAPrIsn7jrPZWAn4DWsiwnSpJUXJbluPudt6DtFBU8y6g38svnG9i0bAc6fw2dhranVa+mYkJa8Ah9moFtK3ZnLlus3aJ6gfks5mnrvyRJTYDxsiy3v/PndwFkWf7wrvdMA87IsvxldoMSCV0QBCHn8tqxKBK4etefo4F7lwlUvnOhHYCSjC+A350EMhgYDFCmTP4sQxKEgibuSjzbVu7BZrXRpGsDl/eFFQovV02KqoBKQCsgCtgqSVItWZZv3/0mWZa/AL6AjDt0F11bELzGbws38tlrS5DljDXPX72/jGfHdqfve909HZrgA7IzKRoD3N2vKerOsbtFA2tlWTbLsnyRjDH3Sq4JURB8w82YBD57bQkmgxmz0YzFZMFkMPP9lJ+5dPzqg08gCA+QnYS+D6gkSVJ5SZI0QG9g7T3vWU3G3TmSJIWRMQRzwYVxCoLX27V2v9OJNYvZwtYVuzwQkeBrHjjkIsuyRZKkEcAfZIyPL5Zl+bgkSROB/bIsr73zWjtJkk4AVmC0LMsJ7gxcEAqKi0cvs2zqGi4fv0rlBg/R662uRFZ0HBfPav3Bv8Mvgnvdup5I/NUEoqqUIiDI39PhuIVocCEIeXBk6wnee2IKZoMZm01GoVSg9dMwc/tkKtQua/fe+OgEBlR+BZPBbHdc46dh7p4P861eSWFj1Bv56Lk57Fl3EI1OjdlopscbnRkwqXeBWYqYE6LBhVAgnd53jveemELvqCGMbjOBo9tOejqkHJv98sKMejF3+r3arDb0qQY+f+Mrh/eGR4Uy9NP+aHRqVBpVRgE4Pw2933lKJHM3mjVsIXvXH8RsNJOWlI7JYGblzN/4Y8kmT4fmcuIOXfCIY9tP8k6HyRjT/ytxq/XTMG75m7kqxuUJJqOZzgHPZibzu2l0an5Ld75h+vqlOLat2I3VYqVZt4aUrhLp7lALLaPeSLdiAzEbzQ6vla5SisUnZ3kgqrzJ6zp0QXC5z9/4yi6ZAxj1Jj4bucRrErpKrUStVTutux4YHJDlz5UsV5xnCnjVPl+RnmIAnN+0Jt1Mzt9g8oEYchE84sKRK06Px56/7jUt4hQKBR1fbIPGz756o9Zfw9Mjn/RQVMLdgsODKBoW5HBckiRqebj5uzuIhC54RHC44y8ZgH+QP0qVMp+jyb2Xpj1P064NUOvUBBT1R61V07ZfK3EHXkBIksSrn72E1l+TWf5WqVLgV0THCx/09WxwbiCGXASP6P3OUyx8+zu7LkVafy3dX+/kVSsPNFo1Y74fya3riVy/GEdkpQind4SC5zTpXJ/pf49n2UeriDl7nRrNqtDr7aeIKF/C06G5nJgUFTxClmW+nbSCnz5ek/Fnm0yX4e158aPnvKIZr5A7JoOJk3vOovPXUqleBfHfOhfyVG3RXURCFyDjFzzhWiIhJYPR+Ws9HY7gRluW7+KTFz9DkiRkm0xgcABTfnuX8rXKPviHhUxiHbpQYGl0GiIqlMh2MpdlmZUzfqVX5GCe8OvDq03f48TuM26OUsirq6dj+HjgXPQpBtKT9ehTDcRHJzD68YleMwnuDURCF7zKove+Z8m4ZdyKTcRstHBy91neenwi5w9f8nRown2sX/QXFpNj31iz0cyBjUc8EJFvEgld8Br6VD2rZ6+zm0iFjI7s305a4bLr2Gw2Ni7dwmuPjmFYvbf4afpajHrjg39QyFLi9SSsFseELttkkhNSPBCRbxKrXASvcePyTadLGmVZ5tyhiy67zvQXPmPbit2ZTauvnoph8487mL1zCiq1+JXJjcad6rF91R6HRuAWs5WHW/reenBPEXfogtcIjyrmdLxVkqBs9SiXXOPKqRi2/LTLLvEY9SaiT19jx+p9LrlGYdSsW0PK1yqL9q65El2Alq4jOlC8THi2zmFIN3LhyGVuxye5K0yvJ243BK8RUDSA9oNas+GrTXZlAzR+Gp4b18Ml1zi27aTTdfD6VAMHNh6m5TNNXHKd+zl/+BKXjl0lslJJqjSo6FXr8rOiUquYvmk8G77azKZl2/EL1NFpSDsaPZm9Mg8/fryGpROWo1QpMBstNO5Uj7e+HiFWRt1DJHTBpcwmM4f+OoY+Rc/Dj9UgOLyoS88/fNZAAoP9WT1nPYZUA5GVSzFi9iCqNnRNg6zgEkVRKh0fXNVaFeGlQ11yjawY9Ube7zqV4zvPoFBIyLJMmWpRTNs4joCiWdeG8RYarZpOQ9rSaUjbHP3cluW7WDphud3cyZ7fDjBj8Hze/fY1V4fp1cQ6dMFlTu87x7sdp2RMfskZnXgGTu5Djzc6u/xasixjs9pcXibAbDLTt8wwkuKT7BpSaP21LD45k+Klw1x6vbt98dZS1sxdb1cvXa1R0bxHE9799lW3XbegG1ZvNOcOXXI4rtaqWRG3CP8ifvkflAeJdeiC21nMFt7tOIWUW6mkJ+tJT9FjMpj56v1lnNxz1uXXkyTJLTVf1Bo10zeNp1TFCLT+WvwCdRQND2LCqtFuTeYAvy/+26H5hdmU0Z7OanVcIVJY3LrufMxcoZRIuZWaz9EUbGLIRXCJQ38fc7oszWQws+7LP6nWyHt6hpetFsWSU7O4evoaJoOJ8rXKoFS6v2CYyeBYhhfAZrFmPI3kQwwFUe0W1di6fJdD3Xmtv5awqGIeiqpgEnfogkvcuxztX7JNJi0pPZ+jyTtJkihTNZKKj5TPt0TaoH0dFAr7CVBJgqqNKqHWqPMlhtxKjEviq3E/MLL5WD4eOI8LRy677Nz9J/ZGF6hDcdfchtZfy8szBxbIL7l9vx9i5KNj6R01hAndp3Px2H+loi1mC7EXbpCWlOaWa4sxdMElkhNS6F16COZ7hgx0AVpGLXqZlj2beigy73HjcjzDG7yDIc2AUW/KbFU3c/vkAt2iLj46gWF1R5OeYsBsNKNQKlBrVYz7yXXdp2Iv3OD7D1ZydPspSpYrTp93uvFwqxouObcrbfhmc2ZbQsi4MdD6a5m9czIndp9h4VvfYrVYsVpstHymCSMXDEbrl7OVOqI4l5AvVs9dz5fvfJvZMFkXoKVa48p8uH6MV9U496SUxFR+X/w3p/edp0LtMnR8oQ0hJYI9HdZ9TX/hMzZ+swWb1WZ3PLRUCN9fmV9oKiparVZ6RrxE8k37na+SBJXrV+TS8at2K3U0OjXNuzfmnaU5m/AWCV3IseSEFPb/8Q9KlZIGHetkeyXBmQPnWbfwL1KT0mjRvTHNnmpYoJK5UW9k9Zz1bFy6BaVSSYcXWtN5aDuxAzQPekcNJuFaosNxjZ+GJadmuX0yuaC4ee0W/Su9gslJS0KlSul0jkmtVbP8+sIcLUsVPUWFHFm/+C/mjliEUq0EJGxWG+N+fJ1GT9Z74M9WrvcQles95P4gc8FqtTK6zQTOH76c+Uu36N3v2bf+H6b89q5PbODxhMCQAKcJXbbZCtWSwiIhAZDVDXIWHy2lWsnt+GSX7TMoHM9Cgh2r1cq2n/cwpe9MPh08325ZYcy5WOa+shiTwYw+xYA+RY8x3ciknp+SkujdS8T2/3GYS8eu2t1BGdONHN12wi1LKwuL7iM7oQuwHwdWaVTUa/fIfZtl+xqtn5Z2/Vuhdegxq6Vqw4oOE94ASqWC4mVc9wQjEnohY7VaGddlKtP6z2Hzsh38vvhvRrcZz0/T1wLw13fbnD4aSgrJ62uZHNt2En2qweG4xWzh+I7THojIN3QY1JonX3o8s6+q1k9D1YYVefvrEZ4OLd+9PGsgbZ5rgUanRhegxT/Ijxc+7MuoRS+jDdDaJXWtv5ZBH/R16QomMeRSyOz59SBHt53IXGYo22SM6Sa+fn8ZbZ9vgTHd6DSh22yy07FBbxIaWQytv8auDgxkjGOGlgrxUFTeT5Ikhn46gF7vdOPi0SuERxWjdJVIT4flEWqNmtcXDGHI9H4kxScTFlUsM2F/tm8qX//vR47tOE14ZDH6julO404PHsbMCZHQC5ntq/ZgSHVcM65UKTn011Gadm3I2nl/YLin5jiyTIOOj+RTlO7Ruu+jLBnzg8NxlVpFs6caeCAi3xJSvCghbWp5OowCwb+In8P8QVTlUoz54XW3XlcMuRQy/kF+TsfyJElCF6ijepPKtOrVNHNMVFJIaP01PtElPahYEaZuHEeJsuHo/LVo/TREVY7gk80TcrwWWBAKIrFssZA5989FRjYbi/Ge4ZOAov78FLsQjU6DLMv8s+kYW37aiVKtpO3zLV1WzbAgkGWZmLOxKJQKIiqUEKtbBK8i1qELdtbMW8+C0UtRq1UggUKhYMpv71K9SRVPhyYIwgPkOaFLktQBmAUogS9lWf4oi/d1B1YADWRZvm+2Fgnds5ITUvhn0zG0/lrqtKmFRluwa4UIgpAhTxuLJElSAvOAtkA0sE+SpLWyLJ+4531FgNeAPXkPWXC3oNAitOjh/u47giDkn+xMijYEzsmyfEGWZROwDOjq5H2TgKmA40JfQRAEwe2yk9Ajgat3/Tn6zrFMkiTVBUrLsvybC2MTBEEQciDPyxYlSVIAnwJvZuO9gyVJ2i9J0v74+Pi8XloQBEG4S3YSegxQ+q4/R9059q8iQE1gsyRJl4DGwFpJkhwG7WVZ/kKW5fqyLNcPDw/PfdSCIAiCg+wk9H1AJUmSykuSpAF6A2v/fVGW5SRZlsNkWS4ny3I5YDfQ5UGrXARB8DxZlrl1PZHU2+7poCPkrweucpFl2SJJ0gjgDzKWLS6WZfm4JEkTgf2yLK+9/xkEX5OSmMrBP4+i1qio27Y2On+xy9Ibndh9hmn95xJ35SayLFPz0aq8s/RVQiNEXRtvJTYWCTmSUSt9MSq1EqSM4l7jfx5N3cdrezo0IQduxiQwqNpIu+qTSpWCiIdKsvjETLF7tgC73zp0UctFyLboM9fu1Eo3kZ6iJz1Zjz7VwP+6TSMtOf8bQcuyzOn959m/4bDbmu76qt8W/onFbF9V02qxkRBzi6PbTnooKiGvRLVFIdv+/HYrVrOTWumSxO5fDtDm2eb5Fsu189d5t8NkEm8koVAqMBstvPBhH55+rVO+xeDNYs7EYjaanb5243LeVqDZbDa2/7yH3xf/jc0m065fS1r2aopSWXBaEfoqkdCFbEtP0WOzOq+VbkjLv/1ksizzbscpxF6MQ7b9N2S4eMwyKtapQO0W1V1+TavVyu24ZAKD/X2iMmOtFtXZ9cv+zLr4/7JabVSun7cWgtMGzGPHqj2Z5z6+4xRbV+zifytHi6EcNxNDLkK2Ne3SAK2TCVDZZqN++/yrlX724AUSr9+2S+YAJr2RNXPXu/x6G5duoWfES/SrOIKnQwcyc9gCzCbnd7fe4vHnmhMUWiRjLuQOrb+Ghh3rULZaVK7Pe/bgBbb/vMfui8KQZuTAxiMc33EqTzELDyYSupBtD7eqQeNO9f6rlS5JaP219Hr7KUqUzb99BamJaSiUjh9dWYbb8ckuvdb+DYeZNWwhyTdTMOlNmAxm/vxmK3OGf+nS6+Q3v0A/5u37iCdeepxiESFEVChBv/G9GLssbw0YDv11FKvZ4nDckG7kwJ9H8nRu4cHEkEs+sFqt7Fq7n92/7KdIaBE6DGqdp7sgT5Ekife+H8ne9YfY/OMONDoN7fq3okbT/C27W7VRJSwmx6Sh9dfw6NONXHqt7yatwHhP9yaj3sSf321j6KcDvLqrfXB4UV6Z+yKvzH3RZecsUiwQlUblMOGq0aoJKlbEZdcRnBN36G5mMVt4u+0kpvabyx9fbWbVrN8YXv9t/vx2i6dDyxVJkqjWqBKV6z+Ef5Aft+OSnPYgdSf/In68OPU5tP4a/h2S1fprKFmuOB0GtXbpta5finN6XKlUkHjjtkuv5Quad2/sdJxcUiho1buZByIqXMQdupttWraD0/vOZY4pWi02rBYTM4d+QbNujfAL0Hk4wpw5ve8cbz0+EavFilFv4tcFGyldOYJPtkzM17/LUyM6UrFOedbM/Z3bcUk0faoBHQa1dnkM1RpXYvuqvQ7j9QqFguJlwlx6LV8QGBzA5F/fZXz3jzNXRCkUCsYse52Q4kU9HJ3vEwndzTYt2+GwkgAymjIf236KBvk4mZhXsiwzufcM0lP0mccMqQYun4hm5ae/8Ny4Z/I1nprNqlKzWVW3XqP/hF7s++MwxjQD/+7B0/pr6T+pV2Y3d8Fe7RbVWR77JSd2ncFms1G9SWXxb5VPxJCLm/kFZLHETQatnyZ/g8mj6xfjSLzuOMxgMpj589ttHojI/cpWL83sHZNp9GQ9ioYHUeHhsrz11XCefvVJT4dWoClVSmo1r8bDLWuIZJ6PxB36fejTDPzy+Qa2/LSTgKL+dB3egaZdG+RoLe2Tg9uyd/0hh7t0jZ+GGs28q4enUqUgq1IRdy9/8zXla5Vl0tp3PB2GIDyQSOhZMBlMvNrkPa6dv4FJbwLg5O4zdB7WnsHTns/2eeo+XpunRz7J8um/oFQrUUgSSlVGU2Zv2zlXvEw4kZUiuHTsCnfnda2/ho4vtvFcYIIgAKI4V5Z+X/w3815b7HBnrdaq+ebcHMIiQ3N0vvjoBP75+xgBwf7Ub/+I1zZlvno6hjdavI/RYMJistx5tK7OxDVvoVKL+wNBcLc8NYkurPasO+h0MlOtUXF85xlaPpOzBsvhUaG07dfSVeF5TOkqkXx3ZT671u4n4dotqjWuTNWGFcWWbkEoAERCz0JoqRAUSgU2q83uuIxMcHiQh6IqGDRadY6/0ARBcL9Cs8ol7upNZg5dQL+KI3i9+Th2/XL/4Z7OQ9uh1th/30mSRGBwALVaVHNnqIIgCLlSKO7Q46MTGFpnNOnJeqwWK7EXbnC2z0UGTeltV27VarWy9rM/WPvZHxhSDdRuWZ3jO06DBDarjfCoUCb98g4KRaH5HhQEwYsUioS+bOrqzGT+L2O6kSVjl/Hk4LaZ5VCn9pvLzjX7Mmt33I5LIqRkMG99NYLg4kUpWz1KjBULglBgFYpbzX/+Pua03ohCqeDqqWsARJ+NZcfqvXaFmCxmK8kJqVw+GU25GqVFMhcEoUArFAk9PKqY0+MWk4XgEhn1Jc7sP49S5fjPYUw3cmTzcbfGJwiC4Ao+kdCtFiuXT0Zz89otp6/3evsph8YMaq2ahx+rSVipjGRfvHQoOFmSr9KoKFWxpMtjFgRBcDWvT+jbft5Dz4gXGdHwXfo9NII3Wr7vUNa0TutaDJ89kICi/vgF6lBr1dRr9zBjfhiZ+Z4azaoSFhXqcJeuUivpNKRdvvxdBEEQ8sKrd4qe++ciIx8dizHdlHlMqVJSvlYZPj8wzeH9ZpOZa+dvUDSsCMHhjqU8b11P5MNnZ3N8xykkhUSxiBBGLxnulh6VQsGQlpyOSW8iuHhRMUcieAWf3Sm6evY6zAb73o5Wi5XoM9e4cOQyFWqXtXtNrVHft1NQsZIhfPzX/0hOSMGoNxEWWUz8kvuIa+evc/1iHGVrlCY0IoTkhBSmDZjLgY1HkCQIiwxl1OKXxZe34NW8OqFfvxSPzeb4hKFUKUm4dsshoWdXUKholeUr9Kl6JnSfztHtp1BrVJiNZlo/25xzhy5y6eiVzFZpsRduMOaJD1hweDqlHhJzJoJ38uox9Lpta6NxUlPcbDRTqV4FD0QkFDSzh3/Jka0nMelNpCWlYzKY+eu7rVw6dtWh76XFbGHNvN89FKkg5J1XJ/TOQ9sRdKcp7b90AVqeevUJp2PkQuFiMprZ8tMuzEb7YTmzweK0M73FnDFcJwjeyquHXIqEBPL5wWksm7qaXWv3U6RYIN1HdqJVr6aeDk0oAMwGEzabzelrztYCaPw0Ygxd8GpevcpFEO5HlmUGVn2NmLOxdsclhURYZDGSE1IzdwYrVQqCQouw6MRMioQEeiJcQciW+61y8eohF+E/Wd2JFmaSJPH6F0PQ+mtRKDM+6mqNioAgf6ZuGMegKX0o9VAJgosH0bZfSz47ME0kc8GriTt0L2a1Wlk6YTmr56wnLSmdcjVLM2L2CzzcqoanQytQrpyKYeWMX7hyMobqTarQ7bUnMncIC4K3ud8derYSuiRJHYBZgBL4Upblj+55/Q3gRcACxAODZFm+fL9zioSed7NeXsjGbzbbbazS+muZsXUileqKVT6C69hsNn5fvInVc9ahTzHQ9KkG9H3vaYqGFe5mL56QpyEXSZKUwDygI1Ad6CNJ0r0zR4eA+rIs1wZWAI7bNAWXSr2dxoavNtklcwCT3sR3U1Z6KCrBV816eSGfjVzCxaNXuH4pjrWf/cHL9d8mLTn9gT+rT9WTGJeEp0YDCpPsjKE3BM7JsnxBlmUTsAzoevcbZFneJMvyv/9ldwNZb8cUXOLG5Xi75Zr/kmWZS8eueiAiwVfFXYln4zdb7EtLmywk3UzmjyWbsvy5tKQ0JvSYTvewQTxbdij9K43gn03H8iPkQis7CT0SuDtDRN85lpUXgPXOXpAkabAkSfslSdofHx+f/SjzWUpiKqf3n+d2fJKnQ8lSyXLhWEyOa6klhcRDj5TL/4AEn3V6/wWHdowAxnQTB/86muXPje38EXt+PYDZZMFstBB7IY6xnT/i6ukYd4ZbqLl0lYskSc8B9YGPnb0uy/IXsizXl2W5fnh4uCsv7RI2m415ry2md+Rg3np8An3LDGPagLlYnGxC8bSAogF0GtLWoSywRqfh2THdPRSV4IvCIotlWWKjVIUSTn/m8slozh68gPmemw6j3sjSCcvdEqeQvYQeA5S+689Rd47ZkSTpcWAM0EWWZeO9r3uDFZ/8wvpFf2MymElP1mM2mtm6fBeL3vve06E5NeST/jw3rjvBxYNQqhRUaVCRaRvH5bqGjSA4U7VhRUqUDXMsLa1R0WV4B6c/c+NSPCq1k32LMmxdscuhxLXgGg9c5SJJkgo4A7QhI5HvA/rKsnz8rvfUIWMytIMsy2ezc+GCuMqlV6mXuHXd8YOmC9CyNnmpqLwoFFq3ricyudcMTu09i0KpJDDYn1GLh1O/3cNO338zJoHnHxrhdFhQoVTQ552nGDCpj7vD9kl5Kp8ry7JFkqQRwB9kLFtcLMvycUmSJgL7ZVleS8YQSyCw/E7SuyLLcheX/Q3ySUpimtPjxnQTVovV+R2HIBQCxUqG8OmWiSTeuI0+1UDJ8sVRKLJ+wA+LDOXhVjU4sOGww2s2q40Tu7N13yfkULYylCzL64B19xx7/67//biL4/KIqg0rcnTbSYfjpatFimQuCEBIiWBCnA+bOxj6ST+G1X3LoaqlSq2kfM0ybohOEFv/7zJsxgB0Af9tE5cUElp/La/OfdHDkQmC9ylXoww1mlVFrbW/GVJp1Dz1akcPReXbREK/S6W6FZi3byptnm1O2epRtOjRmJnbJ4mt9IKQSxPXvE3Lnk1Ra1QolArK1y7L1I3jiCifzdt8IUdELRdByCWrNWMoQalUejiSgs9itmA2WfAL0Hk6FK/nsz1FBcETEmITmTn0C/atP4gsQ93Ha/P6gsEUL1Pw9lYUFCq1SsxD5QMx5CIIOWAxW3it6Rj2rT+I1WLDZrVx8M8jvNJkDEa9V26/EHyISOiCkAO7fz1A8q0UrJb/6s/brDb0KXq2rdzjwcgEQSR0t5JlmbWf/U7PiJdop+zJgCqvsvvXA54Oy+dZrVYuHb/KjcuurxcUfSYWk97scFyfahD9SAWPE4Nad0lP0bN1+S4SriVSrUll6rSumavdoVaLlYN/HWXD15vZuWYfJn1GiduYs7FM7vUp41e9leUOu8LMZDCxZNwy1n/5F8Z0E7VbVmf47EGUqXq/WnD29qw7yMcD52HUm7BZrJStUZrxK0e5bHy7fM3SaPzU6FPs11b7BerE2mrB48QqlzvO/XORUY+Nx2qxYtSb0PlrqVi3Ah/9MRaNVp3t80Sfucao1uNJT9ajTzU4fU/lehnLI4X/pCWnM6nnpxzdegKTIeMOWJLAP8ifRSdmEhoR8sBzRJ+5xtC6o+1qxCuUCkqWL85Xp2e7pHSD1WplcO03uXb+Rua2dqVaSXhUKItPzkStyf5nRRByQ/QUfQBZlpnU81PSktIxpBmRbTL6VANn9p1j9RynlYCzPM/Yzh9xK/Z2lskcIPrsdVeE7RPirsTz5mP/o3vYQA5sOJyZzAFkGUwGM7989nu2zvXL/A1YTPZ3zjarjcTrtzm+45RL4lUqlczcPpnHn2+BXxEdugAtj/VuxpzdH4hkLnicGHIBYi/cICHmlsNxo97Ehq820XNU9srSXDkZTULMrQd2ZomqHJGrOH2NxWzhtUfHcSs2EZvVeZNrs9HM6f0XsnW+G5fjsVqsDsclSSIh1nXV/YqEBPLmwmG8uXCYy84peMbe9YdY+PZSos/EEh5VjP4TetPm2eaeDivXxB063P9RPFNskAAAELFJREFUPAeP6YZ0U2bZgKxo/TQMmiKqzAHsXXeItKS0LJM5gFqjomKdctk6X73Ha6ML0Doct5gtVGtUMbdhCj5q3x//MLHHdC4du4rFlNGAY8aQBaz78k9Ph5ZrIqEDJcsXJywq1OG41k9D+wGtsn2ehx4ui0Ll/J9UkiCqSinG/fQG9dqKCVGA6xfjnJZXvZtaq6bLy85rbt/r8X4tKRYRgvquOQ9dgJb2g1qLTT+Cg0XvfodRb9+T15huZPGYH7y2/6kYciHjDn3sj68zuvUELGYLRr0Jrb+WyvUq0HVE9osIqdQq3v76FSb3/hSr2YrFbEUXoCWyUgQzt09G5+9491iYVapXAaVahdnoJKlLUKNpVV6d9yLhTr5snfEL0DFv70esmPErW5fvwj/Ij6dGdPTqR2jBtW5eu8X2lXswGUxcPeW8FV5qYhqGNAN+gX75HF3eiVUud0lP0bN1xW4Srt2iepPKPPJY7pYtxpyLZf2XfxEfnUCDDnVo2bOJmDBzQpZlXm8+jrMHL2ROhqo0KkqUDWPB4elodeIL8H5kWc74t9ObqNygYo5WYxVGm37cwfSBn4EENmvGDRdO0l9gSAAr4xfft967J91vlYtI6IJHGfVGvpu8kg1fb8ZmtdHymab0m9CTIiGBng6tQLt49DJjOn1IamIakkICGUYtGU7zpxvl6DzXL8Xx3aQVHNl2kvCoUHq/080n90ikJKbSO2pI5p6QrGj9tQyY1Iser3fOp8hyTiR0QfAhZpOZPqWHkhSfbHdc66dhweHpRFbM3iqq2Is3GFb3LfSphsyJaa2/huGzBtHxhTYuj9uT/vpuG7OGfeF0ObEuQIsx3UiR0CI8N7YHT73SMfPJ/Oi2k6yc+Su3YhNp3KkeXV7uQGBwQH6Hb0dUWxQEH3JgwxHMRsfyA1aLlfWL/uLFD5/L1nm+nbjCLplDRrvFBaO+4fHnW/jUMGFWN66SJNFuQCuGfToApUppN8T664INzH/zG4zpGUXXzv9zid8W/sn8gx8X2CfIgjlIJLjV5ZPRjOvyEV2D+/N8heGsnrsemy3rpYNCwZKckILN5pigLGar0ybnWTm85bjTJaNWq40bl1xfB8eTGnasY1dQ7V9afw2t+zRHpVbZJXNDupEFo/5L5pCxyS3xelKONhvmN5HQC5nYizd4tfF77PntIOnJ6Vy/FMeX73zHF6O+8XRoQjbVblkdm5MNVH6BOho9US/b58mqnILVbCUorEiu4yuIgkKL8PrCIWj8NKi1Gd2TtP4anhzSlhpNqzi8/8LhS073lJiNZnatLbhDxSKhFzI/TVuDUW+yewQ1phtZ+/kGkm+leDAyIbtKlivOk4Pb2m2i0vprKVezDI92a5jt8/R+p5vDUlq1Vk3jTvUIKuZbCR3g8WdbsOTULAZN6Uu/8T2ZvfMDhk7v7/S9QaFFnO46BggpWdSdYeaJGEMvZE7uPuv0g6rWqog+E0v1xr73i+yLhs0YwCOP1eSX+RswpBlo3edR2g9qjVKV/XZ4TTrX54WP+rL4vR9AAovJSsMn6jB6yctujNyzipcOo8cbD17BElW5FGWqRnL+8GW7YSmtv5buIzu5M8Q8EatcCpkpfWawZfku5HvGYDU6NV+fm0tYqWIeikzwFJPBxLXzNwgpUZSiYUGeDqfAuHntFmM7fUj0mWsoVUqsZisDp/TxeEIv1KtcbDYbSTdTCAz296lZ+9zq9dZT7Pplv12JWY1OTcOOdUUyz8Kt64kY9SZKlivukhK8/2/vzKOjqu44/vlNlknYJYsLhCAHsAS0ilSBCohapWi1gNAELctBaVBEa1urpcciImrZCkWLUbCCilLcAiJYFFRERBZBQNTIIlEkATEo2SbJr3+8gWaZkAmZmTfzcj/n5JyX9+7c9/3Ne+839937u/fnL19s2cPujTkkpyTQ45oL69X6Pl5wnP2ffk1ySgKJbU490zY2Lpb2XVMaKtdxJJ7TmnlbprF/1wG+zz9Gp+4daNI8vGePOtqhr3pmDU/+aRGFPxTjihKuy7yaWx+5uV4PhtPoeNG5THr5HmaPy+Jw7hEkysWVN/Xl9jmj7ZYWduQdOMyU9FnkbNmLyyW0TGrBPc+M56f9ugb1vGWeMv42aBrb1u4ABVd0FM1aNWHmO5M5q33yKT+rqjz918W8NGs50e4YPCUeLr7qAv6y+C7im8YFVbdTSU1LIdVuEX7i2C6XDcs3MyV9ZpWWqLuJm+vGXkXmzFFBO2+koKocLyjE3STWvLl4KfqxiOPHimh9VisARnWewKH9+VX6UOOaupm/c1ZQF/taMu01Fk5aUmXhKJdLOO+SjsxZP/WUn1319BrmTphP8fH/h9vFxsVw2eBLue/ZO4Om2RA6GmWCi4UPLKnizMGK5lj+xH8pLT719N/GgIjQrFVT48yxHPnU4f9gSNIYRnYcT0ZKJosffpnv8wpqxGmXe8pZ8dRbQdXz+pOra6wCWFGh5Gzdy9G8glN+dsn016o4c7Dip9cuWc/bi9/DU1pzQpLBOTjWoed9dbjWY8e++zGESpxDmaeMouO1Z2KKVKYOn826VzbiKfFQWuzhu4NHefbBpT4n3XhKy/jmy0NB1VPbksIiQrnn1MsNFxz2HXpaUVbBrN9lMbxdJgc+873KoCHycaxD73jRuT73x7hjOCM5fONIw5GiH4v4++i5XN9iBIPOGMkt3X7PjgCldLOb/NwjbF5dcyp9WWm5z+n1cU3dXHRFt6Bq6jesNzHumsNbye0SSahj4PrC/t1wuXwP3Bb/WExB/g88cOOMgOg0hB+Odehjpg7HXW3ShLuJm9EPZThyULS8vJwtq7ez8uk17Nt5IKB1TxoynbUvrMdT4qG8rIL9u3K5b8AUcr84GNDz2EF+7hFiYn3HBsQ3j69yD0XHRtP6rFb0z7gsqJpumjiYs9onE9fMGsSMjY+lSfN47l00oc4om9FT0olvHk9UjO97XFU5uOcQB/cG9y3DYA+OjXLp1L0DM9Y+wIK/PMfnm/eQ1DaB394/lD5DetotLeDkHTjM3f3u59iRH9AKpaJCuXRgdyYuvqvBP165Xxxkx7rdNVqrnpIyXpn9OnfMvaVB9dtNapc2Prs4omOiuGJ4H1K7tmX5v96kuLCEPkN6knFfzdmVgaZpy6bM+3g6617awCfrPuXsDmfyixGX+/Vm2abj2WRtm86L07J546nVPpOHWF03vmdBNgZ2bficd5asR0Ton/5zzvuZc9IT+hXlIiIDgNlAFPCUqj5S7bgbWAhcDBwBfqOq+05Vp5lYFDjuvGwiuz/MqTajLZYxU4czaMK1Dar7o1Uf81D6LI4XFNY4dn7fLsxcO7lB9YcDCyY+zytzVpwcTHS5hPjm8WRtmx7Rqeuen/oSz015uUYQQFJKIs/tezykMfXhQtY9i8h+fNXJ7yQ2LoYhd/+K0ZPTbVbmPw2KchGRKOAx4JdAGpAhImnVio0BjqpqR2AW8GjDJBv85WheAV9s3lNjAK+ksJRl895scP3tu6b47EuOcUeT1qtzg+sPB0ZPyWD8P8eQmtaWVskt6HNjLx7f9GhEO3OAQXdeS7subYg/0XUTF0N8szgmLr6rUTrzPdv3k/3YSkoKS9AKRSuUksJSls5Y5piBYn+6XC4BclR1D4CIvADcAOyqVOYGYJJ3eykwV0REIzXTagThKS6t9eEsLWp4iFpS2wT6DuvNe0s/OBkGKiK44938+o6BDa4/HBARrhnVn2tG9bdbSkCJbxrH3A8fZn32Jra/s5OklAS/u26cyAfLNuHx0b1WUV7BhmWbSTmvjQ2qAos/Dr0NUHmULReonufqZBlVLRORAiABqBI7KCJjgbEA7dq1O03JhsokpSTS+uwz+HZvXpX90bHR9B0amPGCPz41jnY/OYfX5q6k8FgRF17RjbHTRpilAiKAqOgo+gy+tN6p6ZxIrDsGV5SrxtusK8pFTJwz5mOENMpFVbNUtYeq9khKiuzX2XBBRLh30QTim8UR400SHNfUTXJKIhn3DQ7IOaKio8i4dzAv5GaRfWwRk1/9M207+ZfmzGAIF/oO7eU7pFNxTLCEPy30r4HKK/e09e7zVSZXRKKBlliDo4YQ0LX3eSzYPZuVC97mm5xvuaBfV/qn98YdH9xoDIMhkjgzNYkJj9/KnNuexBUdhQDlZRX8YX5mrck+Io06o1y8Dvpz4Eosx/0RMFxVd1Yqcztwvqpmikg6MFhVh52qXhPlYjAY7OD7/AI2rtiKiHDptd1pkRBZOQAatHyut098PLAKK2xxgaruFJHJwCZVzQbmA4tEJAf4DoicGCCDwdCoaJXUkqtHXm63jKDg18QiVV0BrKi27/5K28XA0MBKMxgMBkN9cOzUf4PBYGhsGIduMBgMDsE4dIPBYHAIxqEbDAaDQ7AtBZ2I5AP7T/PjiVSbhdpIaIx2N0abwdjdmKivzamq6nNmpm0OvSGIyKba4jCdTGO0uzHaDMZuu3WEkkDabLpcDAaDwSEYh24wGAwOIVIdepbdAmyiMdrdGG0GY3djImA2R2QfusFgMBhqEqktdIPBYDBUwzh0g8FgcAhh7dBFZICIfCYiOSJyr4/jbhF50Xv8QxFpH3qVgccPu+8WkV0isl1E3hKRVDt0BpK6bK5UboiIqIg4IrTNH7tFZJj3eu8UkedDrTHQ+HF/txORNSKy1XuPR3yuQxFZICJ5IrKjluMiInO838l2Eel+WidS1bD8w1qq90ugAxALbAPSqpW5DZjn3U4HXrRbd4js7g808W6Pi3S7/bHZW6458C6wAehht+4QXetOwFbgDO//yXbrDoHNWcA473YasM9u3QGwuy/QHdhRy/GBwBuAAD2BD0/nPOHcQj+ZnFpVS4ETyakrcwPwjHd7KXClRH468zrtVtU1qlro/XcDVhapSMafaw3wIPAoUBxKcUHEH7tvBR5T1aMAqppHZOOPzQq08G63BL4Job6goKrvYuWKqI0bgIVqsQFoJSL1zvMYzg7dV3Lq6mm5qySnBk4kp45k/LG7MmOwftkjmTpt9r6Cpqjq66EUFmT8udadgc4i8r6IbBCRASFTFxz8sXkScLOI5GLlYbgjNNJspb7PvU/8SnBhCE9E5GagB9DPbi3BRERcwExglM1S7CAaq9vlcqw3sXdF5HxV/d5WVcElA/i3qs4QkV5Y2dC6qWqF3cLCnXBuodcnOfWJ3KdOSE7tj92IyFXAROB6VS0JkbZgUZfNzYFuwFoR2YfVx5jtgIFRf651LpCtqh5V3YuV37dTiPQFA39sHgMsAVDVD4A4rAWsnIxfz31dhLND/wjoJCLnikgs1qBndrUy2cBI7/aNwNvqHWGIYOq0W0QuAp7AcuaR3qcKddisqgWqmqiq7VW1Pda4wfWqGulZxv25x1/Fap0jIolYXTB7QikywPhj81dYSekRkS5YDj0/pCpDTzYwwhvt0hMoUNWD9a7F7tHfOkaGB2K1SL4EJnr3TcZ6mMG60P8BcoCNQAe7NYfI7tXAIeBj71+23ZqDbXO1smtxQJSLn9dasLqbdgGfAOl2aw6BzWnA+1gRMB8DV9utOQA2LwYOAh6st64xQCaQWek6P+b9Tj453fvbTP03GAwGhxDOXS4Gg8FgqAfGoRsMBoNDMA7dYDAYHIJx6AaDweAQjEM3GAwGh2AcusFgMDgE49ANBoPBIfwPSC82b8+Ii1oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TEST EXITOSO!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4mt1kBECVFB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq2e7UwwYyS2",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿El problema es linealmente separable? justifique su respuesta \n",
        "respuesta_1 = \"No, porque no es posible separar las muestras de cada clase con una linea recta\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYCpYnI0YyS4"
      },
      "source": [
        "## Ejercicio 2: entrenamiento\n",
        "\n",
        "En este laboratorio se va a realizar un procedimiento análogo al laboratorio anterior, pero con el modelo de *regresión logística* que sirve para resolver problemas de clasificación (en principio biclase).\n",
        "\n",
        "Analice los siguientes métodos a la luz de la teoría vista para el modelo de regresión logística: \n",
        "\n",
        "1. función de activación (<font color='blue'>sigmoidal</font>),\n",
        "2.  modelo de regresión logística (<font color='blue'>logistic_regression</font>), \n",
        "3. potencia del polinomio \n",
        "4.  el cálculo del error en clasificación (<font color='blue'>error_logistic</font>)\n",
        "5. el gradiente descendente. \n",
        "\n",
        "Luego de recordar estos conceptos. Complete la función sigmoidal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAQAglStYyS4"
      },
      "source": [
        "#Ejercicio de Código\n",
        "def sigmoidal(z):\n",
        "    \"\"\"Función de activación Sigmoidal\n",
        "\n",
        "    z: es la varible a la que se le va aplicar el sigmoide.\n",
        "       es un array numpy de uan sola dimension\n",
        "    retorna: el valor del sigmiode\n",
        "\n",
        "    \"\"\"\n",
        "    #Complete la siguiente línea con el código para calcular la salida de la función sigmoidal\n",
        "    #s = np.exp(z)/(1+np.exp(z))# Duda : Por que con esta  expresión no funciona?\n",
        "    s = 1/(1 + np.exp(-(z)))\n",
        "\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "hiui_rfgYyS6",
        "outputId": "0f2916b1-c13c-44cf-9ee1-9c4567651452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", sigmoidal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST EXITOSO!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t8dJoLfYyS7"
      },
      "source": [
        "El la siguiente celda se sugiere la implementación, de los siguientes conceptos:\n",
        "\n",
        "1. modelo de regresión logística (<font color='blue'>logistic_regression</font>), \n",
        "2. potencia del polinomio \n",
        "3.  el cálculo del error en clasificación (<font color='blue'>error_logistic</font>)\n",
        "\n",
        "comprenda que hacen estas funciones y ejecute la celda para cargar las funciones, para porder usarlas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-yCVeVQYyS8"
      },
      "source": [
        "def logistic_regression(X, W):\n",
        "    \"\"\"calcula la regresión logistica\n",
        "    X: los valores que corresponden a las caractersiticas\n",
        "    W: son los pesos usadados para realizar la regresión\n",
        "    retorna: valor estimado por la regresion\n",
        "    \"\"\"\n",
        "    #Con np.dot se realiza el producto matricial. Aquí X (extendida) tiene dim [Nxd] y W es dim [dx1]\n",
        "\n",
        "    Yest = np.dot(X,W)\n",
        " \n",
        "    Y_lest = sigmoidal(Yest)\n",
        "  \n",
        "    #Se asignan los valores a 1 o 0 según el modelo de regresión logística definido\n",
        "    pos = 0\n",
        "    for tag in Y_lest:\n",
        "        \n",
        "        if tag > 0.5:\n",
        "            Y_lest[pos] = 1\n",
        "        elif tag < 0.5:\n",
        "            Y_lest[pos] = 0\n",
        "        \n",
        "        pos += 1\n",
        "    \n",
        "    return Y_lest    #Y estimado: Esta variable contiene ya tiene la salida de sigm(f(X,W))\n",
        "\n",
        "def potenciaPolinomio(X,grado):\n",
        "    \"\"\"calcula la potencia del polinomio\n",
        "    X: los valores que corresponden a las caractersiticas\n",
        "    grado: esl grado para realizar la potencia al polinomio\n",
        "    retorna: el valor de X despues elevarlo al grado del polinimoo indicado\n",
        "    \"\"\"\n",
        "    X2 = X.copy()\n",
        "    \n",
        "    if grado != 1:\n",
        "        for i in range(2,grado+1):\n",
        "            Xadd = X**i\n",
        "            X2 = np.concatenate((X2, Xadd), axis=1)\n",
        "    \n",
        "    return X2\n",
        "\n",
        "def error_logistic(Y_lest, Y):\n",
        "    \"\"\"calculo del error logistico\n",
        "       Si es diferente el Y_estimado con el Y_real cuenta como un error\n",
        "       Y_lest: numpy array con los valores de etiquetas estimadas\n",
        "       Y:  numpy array  valor con los valores reales de las etiquetas\n",
        "       retorna: error de clasificación -- numpy array\n",
        "    \"\"\"\n",
        "    error = 0\n",
        "    for ye, y in zip(Y_lest, Y):\n",
        "        if ye != y:\n",
        "            error += 1\n",
        "    \n",
        "    error = error/np.size(Y)\n",
        "\n",
        "    return error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuFVmGRoYyS-"
      },
      "source": [
        "De igual manera, debemos extender nuestro conjunto de datos. Comprende que hace  la siguiente celda de código y ejecutala. **Muy importante ejecutar SOLA UNA vez.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGIrWUZoYyS-"
      },
      "source": [
        "#Aca llamamos la funcion creada anteriormente\n",
        "# para obtener el numero muestras y caractersiticas\n",
        "muestras,caracterisitcas,num_clases = clases_muestras_carac(x, y)\n",
        "#Extendemos la matriz de X para el parámetro independiente\n",
        "unos = np.array([np.ones(muestras)])\n",
        "x = np.concatenate((unos.T, x), axis=1)\n",
        "x = x.reshape(muestras, caracterisitcas+1)\n",
        "y = y.reshape(np.size(y), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6rbFHQxYyS_"
      },
      "source": [
        "recordando lo aprendido anteriormente, dividimos nuestro cojunto de datos y normalizamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F2NBNVwYyTA",
        "outputId": "8d79d9c6-fa90-48b8-9cc7-9fa37dfde165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#Dejamos algunas muestras para el proceso de entrenamiento y otras para evaluar qué tan bueno fue el aprendizaje del modelo\n",
        "random.seed(1)\n",
        "N = muestras\n",
        "ind=np.random.permutation(N)\n",
        "Xtrain = x[ind[0:int(math.ceil(0.7*N))],:]\n",
        "Xtest = x[ind[int(math.ceil(0.7*N)):N],:]\n",
        "Ytrain = y[ind[0:int(math.ceil(0.7*N))]]\n",
        "Ytest = y[ind[int(math.ceil(0.7*N)):N]]\n",
        "# normalizamos\n",
        "Xtrain, Xtest = normalizar(Xtrain, Xtest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:2419: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return (a - mns) / sstd\n",
            "/content/lab1.py:332: RuntimeWarning: invalid value encountered in true_divide\n",
            "  Xtest_n = (Xtest - media )/desvia\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX9X-ocwYyTC"
      },
      "source": [
        "Ahora vamos a completar el código de la regla de actualización de los parámetros del algoritmo de <font color='blue'>gradiente_descedente</font>: \n",
        "\n",
        "\n",
        "$$w_j(iter) = w_j(iter-1) - \\eta \\frac{\\partial E(w)}{\\partial w_j}$$ \n",
        "\n",
        "recordar que \n",
        "\n",
        "$$ \\frac{\\partial E(w)}{\\partial w_j} = \\frac{\\partial E({\\bf{w}})}{\\partial w_j} = \\frac{1}{N}\\sum_{i=1}^{N}\\left( f({\\bf{x}}_i,{\\bf{w}}) - y_i\\right) \\frac{\\partial }{\\partial w_j} f({\\bf{x}}_i, {\\bf{w}})$$\n",
        "\n",
        "Recuerda que debe usar las funciones ya implementadas y no usar **ninguna otra libreria**, adicional a las librerias ya pre-cargadas como numpy.\n",
        "\n",
        "Adicionalmente, dentro de nuestra función, **vamos incluir una transformación polinómica**.\n",
        "\n",
        "\n",
        "Nota: Para el problema de clasificación tenga presente que si ya implementó la regla de actualización de parámetros para el modelo de regresión polinomial múltiple, este punto es trivial, puesto que sólo tiene que incluir la función sigmoidal tal como lo vimos en la teoría."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLtR3kdKYyTC"
      },
      "source": [
        "#ejercicio de codigo\n",
        "def gradiente_descendente_logistic_poly(X,Y,grado,eta, iteraciones):\n",
        "    \"\"\"Gradiente descendente para regresión lineal múltiple\n",
        "    X: Matriz de datos extendida\n",
        "    Y: vector con los valores a predecir\n",
        "    W: Vector de parámetros del modelo\n",
        "    eta: Taza de aprendizaje\n",
        "    grado: grado para usar en la transformacion polinomica\n",
        "    iteraciones: numero de iteraciones maxima\n",
        "\n",
        "    retorna: W el valor de de los parametros de regresión polinomica\n",
        "    \"\"\"\n",
        "    #print(X)\n",
        "    X2 = potenciaPolinomio(X,grado)\n",
        "    \n",
        "    #Tomamos el número de variables del problema leugo de la transformacion\n",
        "    d = np.size(X2,1)\n",
        "    #Tomamos el número de muestras de la base de datos\n",
        "    N = np.size(X2,0)   \n",
        "    #Inicializamos el vector de parámetros\n",
        "    W = np.zeros(d)\n",
        "    W = W.reshape(np.size(W),1)\n",
        "\n",
        "   \n",
        "    for iter in range(iteraciones):\n",
        "       \n",
        "        #Aquí debe completar el código con la regla de actualización de los parámetros W para regresión\n",
        "        #logística. Tenga en cuenta los nombres de las variables ya creadas: W, X, Y\n",
        "        Y_estimado = logistic_regression(X2,W)\n",
        "        \n",
        "        acum = np.dot(X2.T,Y_estimado-Y)\n",
        "        W = W - (eta*acum)/N\n",
        "\n",
        "\n",
        "    #Error en clasificación  \n",
        "    Y_estimado = logistic_regression(X2,W)\n",
        "    error_clasificacion = error_logistic(Y_estimado,Y)\n",
        "    print(\"error despues de finalizar la iteraciones\", error_clasificacion)\n",
        "    return W\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "lhrk1KyYYyTE",
        "outputId": "3ffeaa3f-f6f1-4d61-af3e-7ec9b1f98707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio4\", gradiente_descendente_logistic_poly)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error despues de finalizar la iteraciones 0.52\n",
            "error despues de finalizar la iteraciones 0.51\n",
            "TEST EXITOSO!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjpTN71aYyTF"
      },
      "source": [
        "Finalmente se sugiere la siguiente funcion para evaluar el error del modelo. Entienda su funcionamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhbCT0H0YyTG"
      },
      "source": [
        "def evaluar_modelo (W, X_to_test, Y_True, grado):\n",
        "    \"\"\" funcion que evalua un modelo de regresión usando el error cuadratico medio\n",
        "\n",
        "    W: es un matriz con los parametros del modelo entrenados\n",
        "    X_to_test: conjunto de datos para usar en el evaluamiento del modelo\n",
        "    Y_True: valores reales para usar en el evaluamiento del modelo\n",
        "    grado: valor del polinomio a usar\n",
        "\n",
        "    retorna: el de clasificación.\n",
        "    \"\"\"\n",
        "    X2 = potenciaPolinomio(X_to_test,grado)\n",
        "    Y_estimado = logistic_regression(X2,W)\n",
        "    error_clasificacion = error_logistic(Y_estimado,Y_True)\n",
        "    return(error_clasificacion)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhaV3W7IYyTH"
      },
      "source": [
        "## Ejercicio 3: Experimentar\n",
        "\n",
        "Con la función implementada vamos a entrenar un modelo y calcular su error de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "7wwIVbTDYyTI",
        "outputId": "ed909261-8f50-4f0a-82a3-10ab2575f220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "w = gradiente_descendente_logistic_poly(Xtrain,Ytrain,1,0.0001, 1000)\n",
        "error_test = evaluar_modelo(w, Xtest, Ytest, grado = 1)\n",
        "print(\"error en el conjunto de pruebas\", error_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error despues de finalizar la iteraciones 0.5314285714285715\n",
            "error en el conjunto de pruebas 0.4533333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH00WKqYYyTJ"
      },
      "source": [
        "En nuestro primer experimento vamos a evaluar el rendimiento del modelo usando varias tasas de aprendizaje y grados de polinimios. Vamos a dejar por ahora un numero de iteraciones fijas = 50. Para ello completa la siguiente función."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L4aHWL4YyTK"
      },
      "source": [
        "## ejercicio de codigo\n",
        "def experimentar (Xtrain, Xtest, Ytrain, Ytest, tasas, grados):\n",
        "    \"\"\" funcion para realizar experimentos.\n",
        "    Xtrain: conjunto de datos\n",
        "    Xtest:\n",
        "    Ytrain:\n",
        "    Ytest:\n",
        "    tasas: Es una lista con los valores númericos de tasas de aprendizaje \n",
        "        para realizar los experimentos\n",
        "    grados: Es una lista con los valores númericos de grados \n",
        "        para realizar los experimentos\n",
        "    retorna: un dataframe con el resultados de los experimentos\n",
        "    \"\"\"\n",
        "    numero_iter = 50\n",
        "\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0 # indice\n",
        "    for eta in tasas:\n",
        "        for grado in grados:\n",
        "            W = gradiente_descendente_logistic_poly(Xtrain,Ytrain,grado,eta,numero_iter)\n",
        "            error_entrenamiento = evaluar_modelo(W, Xtrain, Ytrain, grado)\n",
        "            error_prueba = evaluar_modelo(W, Xtest, Ytest, grado )\n",
        "            resultados.loc[idx,'grado'] = grado\n",
        "            resultados.loc[idx,'tasa de aprendizaje'] = eta\n",
        "            resultados.loc[idx,'error_entreamiento'] = error_entrenamiento\n",
        "            resultados.loc[idx,'error_prueba'] = error_prueba\n",
        "            idx = idx+1\n",
        "\n",
        "    return (resultados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "n4Y2qwvnYyTL",
        "outputId": "07a88932-5a9b-4654-9a7f-52045548cdeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio5\", experimentar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error despues de finalizar la iteraciones 0.475\n",
            "error despues de finalizar la iteraciones 0.0\n",
            "error despues de finalizar la iteraciones 0.0\n",
            "error despues de finalizar la iteraciones 0.475\n",
            "error despues de finalizar la iteraciones 0.0\n",
            "error despues de finalizar la iteraciones 0.0\n",
            "TEST EXITOSO!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "PNZ702IVYyTN",
        "outputId": "fe80da1e-a155-4c45-cf92-34e7c4db6654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "tasas = [1,0.1,0.001]\n",
        "grados = [1,2,3,4,5]\n",
        "resultados = experimentar (Xtrain, Xtest, Ytrain, Ytest, tasas, grados)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error despues de finalizar la iteraciones 0.5085714285714286\n",
            "error despues de finalizar la iteraciones 0.40285714285714286\n",
            "error despues de finalizar la iteraciones 0.49714285714285716\n",
            "error despues de finalizar la iteraciones 0.008571428571428572\n",
            "error despues de finalizar la iteraciones 0.008571428571428572\n",
            "error despues de finalizar la iteraciones 0.5085714285714286\n",
            "error despues de finalizar la iteraciones 0.40285714285714286\n",
            "error despues de finalizar la iteraciones 0.49714285714285716\n",
            "error despues de finalizar la iteraciones 0.008571428571428572\n",
            "error despues de finalizar la iteraciones 0.008571428571428572\n",
            "error despues de finalizar la iteraciones 0.5085714285714286\n",
            "error despues de finalizar la iteraciones 0.40285714285714286\n",
            "error despues de finalizar la iteraciones 0.49714285714285716\n",
            "error despues de finalizar la iteraciones 0.008571428571428572\n",
            "error despues de finalizar la iteraciones 0.008571428571428572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0S18dT2YyTO",
        "outputId": "e698c1ca-8f3c-42d9-aecf-016fd7c81e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "# para ver los resultados\n",
        "resultados"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>grado</th>\n",
              "      <th>tasa de aprendizaje</th>\n",
              "      <th>error_entreamiento</th>\n",
              "      <th>error_prueba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.508571</td>\n",
              "      <td>0.453333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.402857</td>\n",
              "      <td>0.446667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.497143</td>\n",
              "      <td>0.466667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.508571</td>\n",
              "      <td>0.453333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.402857</td>\n",
              "      <td>0.446667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.497143</td>\n",
              "      <td>0.466667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.508571</td>\n",
              "      <td>0.453333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.402857</td>\n",
              "      <td>0.446667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.497143</td>\n",
              "      <td>0.466667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    grado  tasa de aprendizaje  error_entreamiento  error_prueba\n",
              "0     1.0                1.000            0.508571      0.453333\n",
              "1     2.0                1.000            0.402857      0.446667\n",
              "2     3.0                1.000            0.497143      0.466667\n",
              "3     4.0                1.000            0.008571      0.020000\n",
              "4     5.0                1.000            0.008571      0.020000\n",
              "5     1.0                0.100            0.508571      0.453333\n",
              "6     2.0                0.100            0.402857      0.446667\n",
              "7     3.0                0.100            0.497143      0.466667\n",
              "8     4.0                0.100            0.008571      0.020000\n",
              "9     5.0                0.100            0.008571      0.020000\n",
              "10    1.0                0.001            0.508571      0.453333\n",
              "11    2.0                0.001            0.402857      0.446667\n",
              "12    3.0                0.001            0.497143      0.466667\n",
              "13    4.0                0.001            0.008571      0.020000\n",
              "14    5.0                0.001            0.008571      0.020000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o0zE_e7YyTS",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿con base a los resultados anteriores, qué efecto tiene el grado en los errores de entrenamiento y de prueba? justifique\n",
        "respuesta_2 = \"A mayor grado, menor va a ser el error de entrenamiento y de prueba, dado que a mayor grado permite que el modelo pueda fijar mas f\\xE1cilmente una frontera para diferenciar cada clase.\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8waNHm0YyTT",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿es normal que los errores de entrenamiento y prueba sean diferentes? justifique\n",
        "respuesta_3 = \"\\\"Si, porque el conjunto al realizar el entrenamiento de prueba es un conjunto de datos   distinto, por lo que el error va a cambiar ante otro conjunto de entrada diferente al de entrenamiento,\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-GEvxpWSMjG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq9B0kEIYyTV"
      },
      "source": [
        "En los problemas de clasificación, es muy importante entender el numero de muestras que el modelo clasifico mal. Esto es necesario observarlo tanto en entrenamiento como en pruebas. Vamos crear una función para esto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnhcuVcTYyTV"
      },
      "source": [
        "#ejercicio de codigo\n",
        "def numero_de_errores (W, X, Y, grado):\n",
        "    \"\"\"función que cuenta los errores de un modelo de regresión logistica\n",
        "    W: vector con los parametros de un modelo de regresión logistica\n",
        "       previamente entrenado\n",
        "    X: conjunto de datos a usar (numpy matrix)\n",
        "    Y: conjunto con las etiquetas verdaderas. (numpy array)\n",
        "    grado: grado usado en el modelo de regresión logistica\n",
        "    retorna: numero de errores (int/float) \n",
        "            (es decir el numero de veces que la etiqueta predicha es diferente a la etiqueta real)\n",
        "    \"\"\"\n",
        "    X2 = potenciaPolinomio(X,grado)\n",
        "    Y_estimado = logistic_regression(X2,W)\n",
        "    numero_errores = np.sum(Y_estimado!=Y)\n",
        "\n",
        "    return numero_errores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "iYkbflSmYyTX",
        "outputId": "3a24b2e2-91b7-4d65-c0eb-5069013281ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio6\", numero_de_errores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST EXITOSO!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-bRi6p6YyTY"
      },
      "source": [
        "Ahora, use la función. Entrene nuevamente un modelo con los mejores parametros obtenidos y calcule cuantas muestras quedaron mal clasificadas. Tanto en el conjunto de entrenamiento y de prueba. \n",
        "\n",
        "Si hay parametros empatados, el modelo que tenga menos parametros deberia ser el mejor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-LG4-DhYyTY",
        "outputId": "1d21ceb1-4ab8-4677-8bb7-76f1f58f0f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# puedes usar el siguiente código para ordenar los resultados y ver los 3 primeros\n",
        "# resultados, usa esta salida, para ver cuales fueron los mejores parámetros\n",
        "resultados.sort_values(by = ['error_prueba', 'grado'], ascending = True).head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>grado</th>\n",
              "      <th>tasa de aprendizaje</th>\n",
              "      <th>error_entreamiento</th>\n",
              "      <th>error_prueba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    grado  tasa de aprendizaje  error_entreamiento  error_prueba\n",
              "3     4.0                1.000            0.008571          0.02\n",
              "8     4.0                0.100            0.008571          0.02\n",
              "13    4.0                0.001            0.008571          0.02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "q81OIPYJYyTa",
        "outputId": "8610bd7f-16e6-4bd8-a69b-215e1af40a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        " W = gradiente_descendente_logistic_poly(Xtrain,Ytrain,grado =4 ,eta =0.001\t, iteraciones = 50)\n",
        " print(\"estos son los pesos para el modelo entrenando \\n\", W)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error despues de finalizar la iteraciones 0.008571428571428572\n",
            "estos son los pesos para el modelo entrenando \n",
            " [[ 0.00000000e+00]\n",
            " [ 1.51166183e-06]\n",
            " [ 8.28030184e-06]\n",
            " [ 0.00000000e+00]\n",
            " [-6.12443732e-04]\n",
            " [-5.41597977e-04]\n",
            " [ 0.00000000e+00]\n",
            " [-1.49781610e-05]\n",
            " [ 9.72790608e-05]\n",
            " [ 0.00000000e+00]\n",
            " [ 5.65175470e-04]\n",
            " [ 5.90749680e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "8VpRyLulYyTb",
        "outputId": "3257780f-dda6-4bfe-ef34-eaefd21fd15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "num_errores_entrenamiento =  numero_de_errores (W, Xtrain, Ytrain, grado = 4)\n",
        "num_errores_prueba =  numero_de_errores (W, Xtest, Ytest, grado = 4)\n",
        "print(\"muestras mal clasificadas en entrenamiento\", num_errores_entrenamiento)\n",
        "print(\"muestras mal clasificadas en pruebas\", num_errores_prueba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "muestras mal clasificadas en entrenamiento 3\n",
            "muestras mal clasificadas en pruebas 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMvTxPJfJk8G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnGyv4JtYyTd",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿por qué se uso el error de prueba para ordenar la tabla de resultados en lugar del error de entrenamiento?\n",
        "respuesta_4 = \"\\\"Porque si se ordena de menor a mayor , el menor valor de  error de prueba nos indica que  el primer  modelo  es el que  mas esta adapt\\xE1ndose para realizar predicciones\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANlQQocoYyTf",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Escribe aqui el numero de muestras que quedaron mal clasificadas en el conjunto de entrenamiento y de pruebas. ¿como calificarias el modelo entrenado?\n",
        "respuesta_5 = \"Muestras mal clasificas en entrenamiento 6 y pruebas 2 , el numero de pruebas mal calificas es menor por lo que  se podr\\xEDa inferir que el modelo esta bien entrenado. \" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcXfuTAALgIX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FZeWG54YyTg",
        "cellView": "form"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Escriba el modelo completo con sus variables y coeficientes de f(**x**,**w**) con la mejor frontera de decisión que encontró. usa los valores del último W entrenado. Recuerda tener presente el grado del polinomio\n",
        "respuesta_6 = \"f(x,w) = (2.98e-0.5)X1 - (1.57e-05)X2 - (5.56e-04)X1**2 - (5.53e-04)X2**2 +(5.95e-05)X1**3 +(7.44e-05)X2**3+(4.83e-04)X1**4+(5.55e-04)X2**4\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "qdlLAktOYyTh",
        "outputId": "60337058-849e-44f3-8e9f-245ab4927001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Todo se ve ok. Asegurate de responder las preguntas abiertas y envia e archivo al formulario ¡buen trabajo!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0DWcBDcYyTj",
        "cellView": "form"
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='1036654402' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = '1017251689'  #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19FgbUXzYyTl"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo del los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KepG_JTvYyTl"
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}